{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62O0y0mmQZt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52078758-34fd-4d9c-c24e-e803c66da99c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined DataFrame shape: (844510, 13)\n",
            "\n",
            "Annotation distribution (after filtering out annotation=0):\n",
            "annotation\n",
            "1    733725\n",
            "2    110785\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Annotation 1 (walk) and 2 (FoG) only - annotation 0 excluded\n",
            "\n",
            "Columns in dataset:\n",
            "['time_of_sample', 'ankle_horizontal_forward_acceleration', 'ankle_vertical', 'ankle_horizontal_lateral', 'upper_leg_horizontal_forward_acceleration', 'upper_leg_vertical', 'upper_leg_horizontal_lateral', 'trunk_horizontal_forward_acceleration', 'trunk_vertical', 'trunk_horizontal_lateral', 'annotation', 'patient', 'recording']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Directory containing CSVs\n",
        "data_dir = \"/content\"\n",
        "\n",
        "# Initialize list for all patient dataframes\n",
        "all_data = []\n",
        "\n",
        "# Loop through CSVs\n",
        "for file in sorted(os.listdir(data_dir)):\n",
        "    if file.endswith(\".csv\"):\n",
        "        patient_id = int(file[1:3])  # Extract patient number from filename s01r01.csv\n",
        "        if patient_id in [4, 10]:    # Exclude patients 4 and 10\n",
        "            continue\n",
        "\n",
        "        df = pd.read_csv(os.path.join(data_dir, file))\n",
        "        df['patient'] = patient_id\n",
        "        df['recording'] = file\n",
        "\n",
        "        # CRITICAL FIX: Filter out annotation = 0 (not part of experiment)\n",
        "        df = df[df['annotation'] != 0].reset_index(drop=True)\n",
        "\n",
        "        all_data.append(df)\n",
        "\n",
        "# Combine all patients into a single dataframe\n",
        "combined_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# Show combined shape and annotation distribution\n",
        "print(\"Combined DataFrame shape:\", combined_df.shape)\n",
        "print(\"\\nAnnotation distribution (after filtering out annotation=0):\")\n",
        "print(combined_df['annotation'].value_counts())\n",
        "print(\"\\nAnnotation 1 (walk) and 2 (FoG) only - annotation 0 excluded\")\n",
        "print(\"\\nColumns in dataset:\")\n",
        "print(combined_df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "# Sampling rate and cutoff\n",
        "fs = 64  # Hz\n",
        "cutoff = 20  # Hz\n",
        "\n",
        "# Butterworth filter coefficients\n",
        "b, a = butter(N=3, Wn=cutoff/(fs/2), btype='low')\n",
        "\n",
        "# List of columns to filter (all accelerometer axes)\n",
        "imu_columns = [\n",
        "    'ankle_horizontal_forward_acceleration',\n",
        "    'ankle_vertical',\n",
        "    'ankle_horizontal_lateral',\n",
        "    'upper_leg_horizontal_forward_acceleration',\n",
        "    'upper_leg_vertical',\n",
        "    'upper_leg_horizontal_lateral',\n",
        "    'trunk_horizontal_forward_acceleration',\n",
        "    'trunk_vertical',\n",
        "    'trunk_horizontal_lateral'\n",
        "]\n",
        "\n",
        "# CRITICAL FIX: Filter each recording separately to avoid boundary artifacts\n",
        "filtered_dfs = []\n",
        "\n",
        "for recording in combined_df['recording'].unique():\n",
        "    # Get data for this recording\n",
        "    rec_df = combined_df[combined_df['recording'] == recording].copy()\n",
        "\n",
        "    # Apply filter to each IMU column\n",
        "    for col in imu_columns:\n",
        "        rec_df[col + '_filt'] = filtfilt(b, a, rec_df[col].values)\n",
        "\n",
        "    filtered_dfs.append(rec_df)\n",
        "\n",
        "# Concatenate all filtered recordings\n",
        "combined_df = pd.concat(filtered_dfs, ignore_index=True)\n",
        "\n",
        "print(\"Filtered columns added.\")\n",
        "print(f\"Total recordings processed: {len(filtered_dfs)}\")\n",
        "print(f\"Final shape: {combined_df.shape}\")\n",
        "print(\"\\nExample of original vs filtered (first accelerometer column):\")\n",
        "print(combined_df[[imu_columns[0], imu_columns[0] + '_filt']].head())\n",
        "print(\"\\nColumns now available:\")\n",
        "print([col for col in combined_df.columns if '_filt' in col])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGkVhXakXT59",
        "outputId": "d3a01448-9511-484f-f6b2-7cfb2e66237e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered columns added.\n",
            "Total recordings processed: 14\n",
            "Final shape: (844510, 22)\n",
            "\n",
            "Example of original vs filtered (first accelerometer column):\n",
            "   ankle_horizontal_forward_acceleration  \\\n",
            "0                                    -30   \n",
            "1                                    -30   \n",
            "2                                    -20   \n",
            "3                                    -20   \n",
            "4                                      0   \n",
            "\n",
            "   ankle_horizontal_forward_acceleration_filt  \n",
            "0                                  -30.006663  \n",
            "1                                  -28.182928  \n",
            "2                                  -23.811963  \n",
            "3                                  -14.354459  \n",
            "4                                   -6.730272  \n",
            "\n",
            "Columns now available:\n",
            "['ankle_horizontal_forward_acceleration_filt', 'ankle_vertical_filt', 'ankle_horizontal_lateral_filt', 'upper_leg_horizontal_forward_acceleration_filt', 'upper_leg_vertical_filt', 'upper_leg_horizontal_lateral_filt', 'trunk_horizontal_forward_acceleration_filt', 'trunk_vertical_filt', 'trunk_horizontal_lateral_filt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def create_window_index_labels_augmented(df, window_sec=2, transition_sec=2, fs=64, overlap_ratio=0.5):\n",
        "    \"\"\"\n",
        "    Augmented version: Uses OVERLAPPING windows to increase dataset size.\n",
        "    overlap_ratio: 0.0 = no overlap (original), 0.5 = 50% overlap, 0.75 = 75% overlap.\n",
        "    \"\"\"\n",
        "    window_size = int(window_sec * fs)\n",
        "    transition_samples = int(transition_sec * fs)\n",
        "\n",
        "    # stride: how many samples to move the window forward\n",
        "    # if overlap is 0.5, we move forward by half a window\n",
        "    stride = int(window_size * (1 - overlap_ratio))\n",
        "    if stride < 1: stride = 1\n",
        "\n",
        "    walk_windows = []\n",
        "    transition_windows = []\n",
        "    fog_windows = []\n",
        "\n",
        "    for patient in df['patient'].unique():\n",
        "        for recording in df[df['patient'] == patient]['recording'].unique():\n",
        "            rec_df = df[(df['patient'] == patient) & (df['recording'] == recording)].reset_index(drop=True)\n",
        "            ann = rec_df['annotation'].values\n",
        "            n_samples = len(rec_df)\n",
        "\n",
        "            # Find FoG events\n",
        "            fog_events = []\n",
        "            i = 0\n",
        "            while i < n_samples:\n",
        "                if ann[i] == 2:\n",
        "                    fog_start = i\n",
        "                    while i < n_samples and ann[i] == 2:\n",
        "                        i += 1\n",
        "                    fog_end = i\n",
        "                    fog_events.append((fog_start, fog_end))\n",
        "                else:\n",
        "                    i += 1\n",
        "\n",
        "            for fog_start, fog_end in fog_events:\n",
        "\n",
        "                # --- 1. Create OVERLAPPING TRANSITION Windows ---\n",
        "                # We define the \"Transition Zone\" as [fog_start - transition_samples : fog_start]\n",
        "                # We slide the window across this zone\n",
        "\n",
        "                # Start sliding from the beginning of the transition zone\n",
        "                zone_start = fog_start - transition_samples\n",
        "                zone_end = fog_start\n",
        "\n",
        "                # Generate multiple windows ending within this zone\n",
        "                # To be a valid transition window, the window must END inside the transition zone\n",
        "                # and START after the zone_start\n",
        "\n",
        "                # Let's slide strictly: distinct windows ending at fog_start, fog_start - stride, etc.\n",
        "                # We work backwards from FoG onset to ensure we catch the critical moment\n",
        "                curr_end = zone_end\n",
        "                while curr_end - window_size >= zone_start - (transition_samples * 0.5): # Allow capturing a bit before\n",
        "                    start_idx = curr_end - window_size\n",
        "                    if start_idx >= 0:\n",
        "                        transition_windows.append({\n",
        "                            'patient': patient, 'recording': recording,\n",
        "                            'start_idx': start_idx, 'end_idx': curr_end, 'label': 2\n",
        "                        })\n",
        "                    curr_end -= stride\n",
        "                    # Limit to reasonable number per event to prevent massive imbalance\n",
        "                    if len(transition_windows) > 10000: break\n",
        "\n",
        "                # --- 2. Create OVERLAPPING FOG Windows ---\n",
        "                curr_start = fog_start\n",
        "                while curr_start + window_size <= fog_end:\n",
        "                    fog_windows.append({\n",
        "                        'patient': patient, 'recording': recording,\n",
        "                        'start_idx': curr_start,\n",
        "                        'end_idx': curr_start + window_size,\n",
        "                        'label': 1\n",
        "                    })\n",
        "                    curr_start += stride\n",
        "\n",
        "            # --- 3. Create OVERLAPPING WALK Windows ---\n",
        "            walk_segments = []\n",
        "            i = 0\n",
        "            while i < n_samples:\n",
        "                if ann[i] == 1:\n",
        "                    start = i\n",
        "                    while i < n_samples and ann[i] == 1:\n",
        "                        i += 1\n",
        "                    walk_segments.append((start, i))\n",
        "                else:\n",
        "                    i += 1\n",
        "\n",
        "            for w_start, w_end in walk_segments:\n",
        "                for start in range(w_start, w_end - window_size + 1, stride):\n",
        "                    end = start + window_size\n",
        "\n",
        "                    # Safety check: Don't overlap with Transition Zone\n",
        "                    too_close = False\n",
        "                    for fog_start, _ in fog_events:\n",
        "                        if end > (fog_start - transition_samples) and start < fog_start:\n",
        "                            too_close = True\n",
        "                            break\n",
        "\n",
        "                    if not too_close:\n",
        "                        walk_windows.append({\n",
        "                            'patient': patient, 'recording': recording,\n",
        "                            'start_idx': start, 'end_idx': end, 'label': 0\n",
        "                        })\n",
        "\n",
        "    # Balancing\n",
        "    n_fog = len(fog_windows)\n",
        "    n_trans = len(transition_windows)\n",
        "\n",
        "    # Limit the majority classes to 1.5x the minority to keep some balance but maximize data\n",
        "    target_count = max(n_fog, n_trans)\n",
        "\n",
        "    # Convert to DF\n",
        "    walk_df = pd.DataFrame(walk_windows)\n",
        "    trans_df = pd.DataFrame(transition_windows)\n",
        "    fog_df = pd.DataFrame(fog_windows)\n",
        "\n",
        "    # Downsample Walk if it's massive (it usually is)\n",
        "    if len(walk_df) > target_count:\n",
        "        walk_df = walk_df.sample(n=target_count, random_state=42)\n",
        "\n",
        "    # Balance FoG and Trans if heavily skewed\n",
        "    min_class = min(len(fog_df), len(trans_df))\n",
        "    if len(fog_df) > min_class * 2: fog_df = fog_df.sample(n=min_class * 2, random_state=42)\n",
        "    if len(trans_df) > min_class * 2: trans_df = trans_df.sample(n=min_class * 2, random_state=42)\n",
        "\n",
        "    window_df = pd.concat([walk_df, trans_df, fog_df], ignore_index=True)\n",
        "\n",
        "    print(f\"\\nAugmented {window_sec}s windows (Overlap={overlap_ratio}):\")\n",
        "    print(f\"Total: {len(window_df)}\")\n",
        "    print(f\"  Walk: {len(walk_df)}\")\n",
        "    print(f\"  FoG: {len(fog_df)}\")\n",
        "    print(f\"  Trans: {len(trans_df)}\")\n",
        "\n",
        "    return window_df\n",
        "\n",
        "# Create datasets A, B, C as per paper\n",
        "print(\"=\"*60)\n",
        "print(\"DATASET A: 2s windows, 2s transition period\")\n",
        "print(\"=\"*60)\n",
        "window_df_2s = create_window_index_labels_augmented(combined_df, window_sec=2, transition_sec=2, overlap_ratio=0.75)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATASET B: 3s windows, 3s transition period\")\n",
        "print(\"=\"*60)\n",
        "window_df_3s = create_window_index_labels_augmented(combined_df, window_sec=3, transition_sec=3, overlap_ratio=0.75)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATASET C: 4s windows, 4s transition period\")\n",
        "print(\"=\"*60)\n",
        "window_df_4s = create_window_index_labels_augmented(combined_df, window_sec=4, transition_sec=4, overlap_ratio=0.75)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inRv0WKCXYGR",
        "outputId": "5deb690a-6044-4988-cf94-3470be77af2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DATASET A: 2s windows, 2s transition period\n",
            "============================================================\n",
            "\n",
            "Augmented 2s windows (Overlap=0.75):\n",
            "Total: 4818\n",
            "  Walk: 2685\n",
            "  FoG: 1422\n",
            "  Trans: 711\n",
            "\n",
            "============================================================\n",
            "DATASET B: 3s windows, 3s transition period\n",
            "============================================================\n",
            "\n",
            "Augmented 3s windows (Overlap=0.75):\n",
            "Total: 3710\n",
            "  Walk: 1577\n",
            "  FoG: 1422\n",
            "  Trans: 711\n",
            "\n",
            "============================================================\n",
            "DATASET C: 4s windows, 4s transition period\n",
            "============================================================\n",
            "\n",
            "Augmented 4s windows (Overlap=0.75):\n",
            "Total: 2787\n",
            "  Walk: 1038\n",
            "  FoG: 1038\n",
            "  Trans: 711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check FoG event durations\n",
        "fog_durations = []\n",
        "\n",
        "for patient in combined_df['patient'].unique():\n",
        "    for recording in combined_df[combined_df['patient'] == patient]['recording'].unique():\n",
        "        rec_df = combined_df[(combined_df['patient'] == patient) & (combined_df['recording'] == recording)].reset_index(drop=True)\n",
        "        ann = rec_df['annotation'].values\n",
        "        n_samples = len(rec_df)\n",
        "\n",
        "        i = 0\n",
        "        while i < n_samples:\n",
        "            if ann[i] == 2:  # Start of FoG\n",
        "                fog_start = i\n",
        "                while i < n_samples and ann[i] == 2:\n",
        "                    i += 1\n",
        "                fog_end = i\n",
        "                duration_sec = (fog_end - fog_start) / 64  # Convert to seconds\n",
        "                fog_durations.append(duration_sec)\n",
        "            else:\n",
        "                i += 1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"Total FoG events: {len(fog_durations)}\")\n",
        "print(f\"FoG duration stats (seconds):\")\n",
        "print(f\"  Min: {np.min(fog_durations):.2f}\")\n",
        "print(f\"  Max: {np.max(fog_durations):.2f}\")\n",
        "print(f\"  Mean: {np.mean(fog_durations):.2f}\")\n",
        "print(f\"  Median: {np.median(fog_durations):.2f}\")\n",
        "print(f\"\\nFoG events shorter than 2s: {np.sum(np.array(fog_durations) < 2)}\")\n",
        "print(f\"FoG events shorter than 3s: {np.sum(np.array(fog_durations) < 3)}\")\n",
        "print(f\"FoG events shorter than 4s: {np.sum(np.array(fog_durations) < 4)}\")\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.hist(fog_durations, bins=50, edgecolor='black')\n",
        "plt.xlabel('FoG Duration (seconds)')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of FoG Event Durations')\n",
        "plt.axvline(2, color='r', linestyle='--', label='2s window')\n",
        "plt.axvline(3, color='g', linestyle='--', label='3s window')\n",
        "plt.axvline(4, color='b', linestyle='--', label='4s window')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "wadsVwNcZ7cD",
        "outputId": "d8e7698c-8dd3-43b1-9920-6b0a322afdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total FoG events: 237\n",
            "FoG duration stats (seconds):\n",
            "  Min: 0.44\n",
            "  Max: 40.53\n",
            "  Mean: 7.30\n",
            "  Median: 5.34\n",
            "\n",
            "FoG events shorter than 2s: 48\n",
            "FoG events shorter than 3s: 72\n",
            "FoG events shorter than 4s: 94\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "\n",
        "def compute_time_features(sig):\n",
        "    \"\"\"\n",
        "    Compute robust time-domain features for a 1D signal.\n",
        "    Handles constant signals safely to avoid histogram errors in entropy.\n",
        "    \"\"\"\n",
        "    sig = np.asarray(sig)\n",
        "    rms = np.sqrt(np.mean(sig**2))\n",
        "    vel_rms = np.sqrt(np.mean(np.diff(sig)**2)) if len(sig) > 1 else 0.0\n",
        "\n",
        "    # Entropy computation\n",
        "    data_range = np.max(sig) - np.min(sig)\n",
        "    if data_range < 1e-6:\n",
        "        ent = 0.0\n",
        "    else:\n",
        "        ps = np.histogram(sig, bins=10, density=True)[0] + 1e-8\n",
        "        ent = -np.sum(ps * np.log(ps))\n",
        "\n",
        "    return {\n",
        "        'mean': np.mean(sig),\n",
        "        'std': np.std(sig),\n",
        "        'min': np.min(sig),\n",
        "        'max': np.max(sig),\n",
        "        'q1': np.percentile(sig, 25),\n",
        "        'median': np.median(sig),\n",
        "        'q3': np.percentile(sig, 75),\n",
        "        'skew': skew(sig),\n",
        "        'kurt': kurtosis(sig),\n",
        "        'zero_cross': ((sig[:-1] * sig[1:]) < 0).sum() / len(sig),\n",
        "        'ptp': np.ptp(sig),\n",
        "        'crest_factor': np.max(np.abs(sig)) / (rms + 1e-8),\n",
        "        'rms': rms,\n",
        "        'vel_rms': vel_rms,\n",
        "        'entropy': ent\n",
        "    }\n",
        "\n",
        "# Test\n",
        "sig_test = np.array([1,1,1,1,1])\n",
        "print(\"Time-domain features test:\", compute_time_features(sig_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Rqq9dDa35P",
        "outputId": "23d2852d-dadc-44b7-a04c-8c685fbccd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time-domain features test: {'mean': np.float64(1.0), 'std': np.float64(0.0), 'min': np.int64(1), 'max': np.int64(1), 'q1': np.float64(1.0), 'median': np.float64(1.0), 'q3': np.float64(1.0), 'skew': np.float64(nan), 'kurt': np.float64(nan), 'zero_cross': np.float64(0.0), 'ptp': np.int64(0), 'crest_factor': np.float64(0.9999999900000002), 'rms': np.float64(1.0), 'vel_rms': np.float64(0.0), 'entropy': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import welch\n",
        "from scipy.fft import fft, fftfreq\n",
        "\n",
        "def compute_freq_features(sig, fs=64):\n",
        "    \"\"\"\n",
        "    Compute comprehensive frequency-domain features using Welch's method and FFT.\n",
        "    Includes all features from the paper (Table 1).\n",
        "    \"\"\"\n",
        "    sig = np.asarray(sig)\n",
        "\n",
        "    # Handle constant signal\n",
        "    if np.all(sig == sig[0]) or len(sig) < 2:\n",
        "        return {\n",
        "            'freeze_index': 0.0,\n",
        "            'power_diff': 0.0,\n",
        "            'total_power': 0.0,\n",
        "            'spectral_centroid': 0.0,\n",
        "            'spectral_entropy': 0.0,\n",
        "            'dom_freq': 0.0,\n",
        "            'fft_mean_mag': 0.0,\n",
        "            'fft_mean_phase': 0.0,\n",
        "            'fft_coef_1': 0.0,\n",
        "            'fft_coef_2': 0.0,\n",
        "            'power_band_05_3': 0.0,\n",
        "            'power_band_3_8': 0.0,\n",
        "            'power_band_8_20': 0.0\n",
        "        }\n",
        "\n",
        "    # ===== WELCH'S METHOD FOR POWER SPECTRAL DENSITY =====\n",
        "    f, Pxx = welch(sig, fs=fs, nperseg=min(len(sig), 256))\n",
        "    total_power = np.sum(Pxx)\n",
        "\n",
        "    # Frequency band powers\n",
        "    p05_3 = np.sum(Pxx[(f >= 0.5) & (f < 3)])    # 0.5-3 Hz\n",
        "    p3_8 = np.sum(Pxx[(f >= 3) & (f < 8)])       # 3-8 Hz\n",
        "    p8_20 = np.sum(Pxx[(f >= 8) & (f <= 20)])    # 8-20 Hz\n",
        "\n",
        "    # Freeze Index (key feature for FoG detection)\n",
        "    freeze_index = p3_8 / (p05_3 + 1e-8)\n",
        "\n",
        "    # Power difference\n",
        "    power_diff = p3_8 - p05_3\n",
        "\n",
        "    # Dominant frequency\n",
        "    dom_freq = f[np.argmax(Pxx)]\n",
        "\n",
        "    # Spectral centroid (center of mass of spectrum)\n",
        "    spectral_centroid = np.sum(f * Pxx) / (total_power + 1e-8)\n",
        "\n",
        "    # Spectral entropy\n",
        "    Pxx_norm = Pxx / (total_power + 1e-8)\n",
        "    spectral_entropy = -np.sum(Pxx_norm * np.log(Pxx_norm + 1e-8))\n",
        "\n",
        "    # ===== FFT FEATURES =====\n",
        "    # Compute FFT\n",
        "    N = len(sig)\n",
        "    fft_vals = fft(sig)\n",
        "    fft_freqs = fftfreq(N, 1/fs)\n",
        "\n",
        "    # Take only positive frequencies\n",
        "    positive_freq_idx = fft_freqs > 0\n",
        "    fft_vals_pos = fft_vals[positive_freq_idx]\n",
        "    fft_freqs_pos = fft_freqs[positive_freq_idx]\n",
        "\n",
        "    # FFT magnitudes and phases\n",
        "    fft_mag = np.abs(fft_vals_pos)\n",
        "    fft_phase = np.angle(fft_vals_pos)\n",
        "\n",
        "    # FFT mean magnitude\n",
        "    fft_mean_mag = np.mean(fft_mag) if len(fft_mag) > 0 else 0.0\n",
        "\n",
        "    # FFT mean phase\n",
        "    fft_mean_phase = np.mean(fft_phase) if len(fft_phase) > 0 else 0.0\n",
        "\n",
        "    # FFT 1st and 2nd coefficients (from the strongest frequency components)\n",
        "    # Sort by magnitude to get strongest components\n",
        "    sorted_indices = np.argsort(fft_mag)[::-1]  # Descending order\n",
        "\n",
        "    # First FFT coefficient (strongest component)\n",
        "    fft_coef_1 = fft_mag[sorted_indices[0]] if len(sorted_indices) > 0 else 0.0\n",
        "\n",
        "    # Second FFT coefficient (2nd strongest component)\n",
        "    fft_coef_2 = fft_mag[sorted_indices[1]] if len(sorted_indices) > 1 else 0.0\n",
        "\n",
        "    return {\n",
        "        # Power spectrum features\n",
        "        'freeze_index': freeze_index,\n",
        "        'power_diff': power_diff,\n",
        "        'total_power': total_power,\n",
        "        'power_band_05_3': p05_3,\n",
        "        'power_band_3_8': p3_8,\n",
        "        'power_band_8_20': p8_20,\n",
        "\n",
        "        # Spectral characteristics\n",
        "        'spectral_centroid': spectral_centroid,\n",
        "        'spectral_entropy': spectral_entropy,\n",
        "        'dom_freq': dom_freq,\n",
        "\n",
        "        # FFT features\n",
        "        'fft_mean_mag': fft_mean_mag,\n",
        "        'fft_mean_phase': fft_mean_phase,\n",
        "        'fft_coef_1': fft_coef_1,\n",
        "        'fft_coef_2': fft_coef_2\n",
        "    }\n",
        "\n",
        "# Test with a realistic signal\n",
        "sig_test_constant = np.array([1, 1, 1, 1, 1])\n",
        "sig_test_varying = np.sin(2 * np.pi * 5 * np.linspace(0, 2, 128))  # 5 Hz sine wave\n",
        "\n",
        "print(\"Frequency features (constant signal):\")\n",
        "print(compute_freq_features(sig_test_constant))\n",
        "print(\"\\nFrequency features (5 Hz sine wave):\")\n",
        "print(compute_freq_features(sig_test_varying))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNvIY1zvc6uq",
        "outputId": "1644149f-0e94-4e86-f1fa-41d03c47a484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequency features (constant signal):\n",
            "{'freeze_index': 0.0, 'power_diff': 0.0, 'total_power': 0.0, 'spectral_centroid': 0.0, 'spectral_entropy': 0.0, 'dom_freq': 0.0, 'fft_mean_mag': 0.0, 'fft_mean_phase': 0.0, 'fft_coef_1': 0.0, 'fft_coef_2': 0.0, 'power_band_05_3': 0.0, 'power_band_3_8': 0.0, 'power_band_8_20': 0.0}\n",
            "\n",
            "Frequency features (5 Hz sine wave):\n",
            "{'freeze_index': np.float64(2786574.357314296), 'power_diff': np.float64(0.9999989608080009), 'total_power': np.float64(0.9999998381706111), 'power_band_05_3': np.float64(3.4886331439406336e-07), 'power_band_3_8': np.float64(0.9999993096713152), 'power_band_8_20': np.float64(1.791321793302065e-07), 'spectral_centroid': np.float64(5.039370952794472), 'spectral_entropy': np.float64(0.8677805278415172), 'dom_freq': np.float64(5.0), 'fft_mean_mag': np.float64(1.6771678699846617), 'fft_mean_phase': np.float64(1.8575289896225382), 'fft_coef_1': np.float64(63.090545973773935), 'fft_coef_2': np.float64(5.662468329418066)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def extract_features_for_window(seg, fs=64):\n",
        "    \"\"\"\n",
        "    Extract ALL features for a single window segment (DataFrame slice).\n",
        "    Includes time, frequency, PCA, and geometric features as per paper.\n",
        "    \"\"\"\n",
        "    feats = {}\n",
        "\n",
        "    # x, y, z signals (filtered)\n",
        "    sig_x = seg['ankle_horizontal_forward_acceleration_filt'].values\n",
        "    sig_y = seg['ankle_vertical_filt'].values\n",
        "    sig_z = seg['ankle_horizontal_lateral_filt'].values\n",
        "\n",
        "    # ===== 1. TIME & FREQUENCY FEATURES FOR X, Y, Z =====\n",
        "    for axis, sig in zip(['x', 'y', 'z'], [sig_x, sig_y, sig_z]):\n",
        "        tf = compute_time_features(sig)\n",
        "        ff = compute_freq_features(sig, fs)\n",
        "        feats.update({f\"{axis}_{k}\": v for k, v in {**tf, **ff}.items()})\n",
        "\n",
        "    # ===== 2. MAGNITUDE FEATURES =====\n",
        "    mag = np.sqrt(sig_x**2 + sig_y**2 + sig_z**2)\n",
        "    tf_mag = compute_time_features(mag)\n",
        "    ff_mag = compute_freq_features(mag, fs)\n",
        "    feats.update({f\"mag_{k}\": v for k, v in {**tf_mag, **ff_mag}.items()})\n",
        "\n",
        "    # ===== 3. PCA COMPONENTS (PC1, PC2, PC3) =====\n",
        "    # Stack x, y, z into matrix (n_samples  3)\n",
        "    xyz_matrix = np.column_stack([sig_x, sig_y, sig_z])\n",
        "\n",
        "    # Compute PCA\n",
        "    pca = PCA(n_components=3)\n",
        "    try:\n",
        "        pc_components = pca.fit_transform(xyz_matrix)\n",
        "        pc1 = pc_components[:, 0]\n",
        "        pc2 = pc_components[:, 1]\n",
        "        pc3 = pc_components[:, 2]\n",
        "    except:\n",
        "        # If PCA fails (e.g., constant signal), use zeros\n",
        "        pc1 = np.zeros_like(sig_x)\n",
        "        pc2 = np.zeros_like(sig_x)\n",
        "        pc3 = np.zeros_like(sig_x)\n",
        "\n",
        "    # Extract features from PC components\n",
        "    for pc_name, pc_sig in zip(['pc1', 'pc2', 'pc3'], [pc1, pc2, pc3]):\n",
        "        tf_pc = compute_time_features(pc_sig)\n",
        "        ff_pc = compute_freq_features(pc_sig, fs)\n",
        "        feats.update({f\"{pc_name}_{k}\": v for k, v in {**tf_pc, **ff_pc}.items()})\n",
        "\n",
        "    # ===== 4. GEOMETRIC/SPATIAL FEATURES =====\n",
        "\n",
        "    # Integrals (sum of integrated acceleration in x, y, z)\n",
        "    feats['integral_x'] = np.sum(np.cumsum(sig_x))\n",
        "    feats['integral_y'] = np.sum(np.cumsum(sig_y))\n",
        "    feats['integral_z'] = np.sum(np.cumsum(sig_z))\n",
        "    feats['integral_total'] = feats['integral_x'] + feats['integral_y'] + feats['integral_z']\n",
        "\n",
        "    # Center of Gravity (CoG) of x, y, z components\n",
        "    # CoG = weighted average position\n",
        "    time_indices = np.arange(len(sig_x))\n",
        "    feats['cog_x'] = np.sum(time_indices * np.abs(sig_x)) / (np.sum(np.abs(sig_x)) + 1e-8)\n",
        "    feats['cog_y'] = np.sum(time_indices * np.abs(sig_y)) / (np.sum(np.abs(sig_y)) + 1e-8)\n",
        "    feats['cog_z'] = np.sum(time_indices * np.abs(sig_z)) / (np.sum(np.abs(sig_z)) + 1e-8)\n",
        "\n",
        "    # Angles of x, y, z components\n",
        "    # Compute angles using arctangent ratios\n",
        "    feats['angle_xy'] = np.mean(np.arctan2(sig_y, sig_x + 1e-8))  # angle in x-y plane\n",
        "    feats['angle_xz'] = np.mean(np.arctan2(sig_z, sig_x + 1e-8))  # angle in x-z plane\n",
        "    feats['angle_yz'] = np.mean(np.arctan2(sig_z, sig_y + 1e-8))  # angle in y-z plane\n",
        "\n",
        "    return feats\n",
        "\n",
        "# Test with first 2s window\n",
        "print(\"Testing feature extraction on first window...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cgtkXJ9c9cv",
        "outputId": "1873391a-e6f2-444a-8fb2-cb8897938f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing feature extraction on first window...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_for_windows_df(window_df, combined_df, fs=64):\n",
        "    \"\"\"\n",
        "    Extract features for all windows in window_df and return DataFrame X and label array y.\n",
        "    FIXED: Properly handles recording-specific indices.\n",
        "    \"\"\"\n",
        "    feature_list = []\n",
        "    labels = []\n",
        "\n",
        "    print(\"Extracting features for windows...\")\n",
        "\n",
        "    for idx, row in window_df.iterrows():\n",
        "        # CRITICAL FIX: Filter by patient AND recording, then use local indices\n",
        "        patient = row['patient']\n",
        "        recording = row['recording']\n",
        "        start_idx = int(row['start_idx'])\n",
        "        end_idx = int(row['end_idx'])\n",
        "\n",
        "        # Get the specific recording's data\n",
        "        rec_df = combined_df[\n",
        "            (combined_df['patient'] == patient) &\n",
        "            (combined_df['recording'] == recording)\n",
        "        ].reset_index(drop=True)\n",
        "\n",
        "        # Extract segment using local indices\n",
        "        seg = rec_df.iloc[start_idx:end_idx+1]\n",
        "\n",
        "        # Verify segment size\n",
        "        expected_size = end_idx - start_idx + 1\n",
        "        if len(seg) != expected_size:\n",
        "            print(f\" Warning: Window {idx} has wrong size ({len(seg)} vs {expected_size})\")\n",
        "            continue\n",
        "\n",
        "        # Extract features\n",
        "        try:\n",
        "            feats = extract_features_for_window(seg, fs)\n",
        "            feature_list.append(feats)\n",
        "            labels.append(row['label'])\n",
        "        except Exception as e:\n",
        "            print(f\" Error extracting features for window {idx}: {e}\")\n",
        "            continue\n",
        "\n",
        "        if (idx + 1) % 100 == 0:\n",
        "            print(f\"  Processed {idx + 1}/{len(window_df)} windows...\")\n",
        "\n",
        "    X = pd.DataFrame(feature_list)\n",
        "    y = np.array(labels, dtype=np.int8)\n",
        "\n",
        "    # Clean NaNs and infs\n",
        "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "    print(f\"\\n Feature extraction complete!\")\n",
        "    print(f\"   Feature matrix shape: {X.shape}\")\n",
        "    print(f\"   Total features: {X.shape[1]}\")\n",
        "    print(f\"   Label distribution: Walk={np.sum(y==0)}, FoG={np.sum(y==1)}, Transition={np.sum(y==2)}\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# ---- Extract features for all datasets ----\n",
        "print(\"=\"*60)\n",
        "print(\"EXTRACTING FEATURES FOR 2s WINDOWS\")\n",
        "print(\"=\"*60)\n",
        "X_2s, y_2s = extract_features_for_windows_df(window_df_2s, combined_df)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXTRACTING FEATURES FOR 3s WINDOWS\")\n",
        "print(\"=\"*60)\n",
        "X_3s, y_3s = extract_features_for_windows_df(window_df_3s, combined_df)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXTRACTING FEATURES FOR 4s WINDOWS\")\n",
        "print(\"=\"*60)\n",
        "X_4s, y_4s = extract_features_for_windows_df(window_df_4s, combined_df)\n",
        "\n",
        "# Display sample\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAMPLE FEATURES (first 20 columns):\")\n",
        "print(\"=\"*60)\n",
        "print(X_2s.columns[:20].tolist())\n",
        "print(f\"\\nTotal feature count: {X_2s.shape[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abtujtx8dADm",
        "outputId": "a245e0dc-bd3c-4d04-decc-ba2252474d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "EXTRACTING FEATURES FOR 2s WINDOWS\n",
            "============================================================\n",
            "Extracting features for windows...\n",
            "  Processed 100/4818 windows...\n",
            "  Processed 200/4818 windows...\n",
            "  Processed 300/4818 windows...\n",
            "  Processed 400/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/decomposition/_pca.py:648: RuntimeWarning: invalid value encountered in divide\n",
            "  explained_variance_ratio_ = explained_variance_ / total_var\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 500/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 600/4818 windows...\n",
            "  Processed 700/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 800/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 900/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 1000/4818 windows...\n",
            "  Processed 1100/4818 windows...\n",
            "  Processed 1200/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 1300/4818 windows...\n",
            "  Processed 1400/4818 windows...\n",
            "  Processed 1500/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 1600/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 1700/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 1800/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 1900/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 2000/4818 windows...\n",
            "  Processed 2100/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 2200/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 2300/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 2400/4818 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 2500/4818 windows...\n",
            "  Processed 2600/4818 windows...\n",
            "  Processed 2700/4818 windows...\n",
            "  Processed 2800/4818 windows...\n",
            "  Processed 2900/4818 windows...\n",
            "  Processed 3000/4818 windows...\n",
            "  Processed 3100/4818 windows...\n",
            "  Processed 3200/4818 windows...\n",
            "  Processed 3300/4818 windows...\n",
            "  Processed 3400/4818 windows...\n",
            "  Processed 3500/4818 windows...\n",
            "  Processed 3600/4818 windows...\n",
            "  Processed 3700/4818 windows...\n",
            "  Processed 3800/4818 windows...\n",
            "  Processed 3900/4818 windows...\n",
            "  Processed 4000/4818 windows...\n",
            "  Processed 4100/4818 windows...\n",
            "  Processed 4200/4818 windows...\n",
            "  Processed 4300/4818 windows...\n",
            "  Processed 4400/4818 windows...\n",
            "  Processed 4500/4818 windows...\n",
            "  Processed 4600/4818 windows...\n",
            "  Processed 4700/4818 windows...\n",
            "  Processed 4800/4818 windows...\n",
            "\n",
            " Feature extraction complete!\n",
            "   Feature matrix shape: (4818, 206)\n",
            "   Total features: 206\n",
            "   Label distribution: Walk=2685, FoG=1422, Transition=711\n",
            "\n",
            "============================================================\n",
            "EXTRACTING FEATURES FOR 3s WINDOWS\n",
            "============================================================\n",
            "Extracting features for windows...\n",
            "  Processed 100/3710 windows...\n",
            "  Processed 200/3710 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 300/3710 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 400/3710 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 500/3710 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 600/3710 windows...\n",
            "  Processed 700/3710 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 800/3710 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 900/3710 windows...\n",
            "  Processed 1000/3710 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 1100/3710 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 1200/3710 windows...\n",
            "  Processed 1300/3710 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 1400/3710 windows...\n",
            "  Processed 1500/3710 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 1600/3710 windows...\n",
            "  Processed 1700/3710 windows...\n",
            "  Processed 1800/3710 windows...\n",
            "  Processed 1900/3710 windows...\n",
            "  Processed 2000/3710 windows...\n",
            "  Processed 2100/3710 windows...\n",
            "  Processed 2200/3710 windows...\n",
            "  Processed 2300/3710 windows...\n",
            "  Processed 2400/3710 windows...\n",
            "  Processed 2500/3710 windows...\n",
            "  Processed 2600/3710 windows...\n",
            "  Processed 2700/3710 windows...\n",
            "  Processed 2800/3710 windows...\n",
            "  Processed 2900/3710 windows...\n",
            "  Processed 3000/3710 windows...\n",
            "  Processed 3100/3710 windows...\n",
            "  Processed 3200/3710 windows...\n",
            "  Processed 3300/3710 windows...\n",
            "  Processed 3400/3710 windows...\n",
            "  Processed 3500/3710 windows...\n",
            "  Processed 3600/3710 windows...\n",
            "  Processed 3700/3710 windows...\n",
            "\n",
            " Feature extraction complete!\n",
            "   Feature matrix shape: (3710, 206)\n",
            "   Total features: 206\n",
            "   Label distribution: Walk=1577, FoG=1422, Transition=711\n",
            "\n",
            "============================================================\n",
            "EXTRACTING FEATURES FOR 4s WINDOWS\n",
            "============================================================\n",
            "Extracting features for windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 100/2787 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 200/2787 windows...\n",
            "  Processed 300/2787 windows...\n",
            "  Processed 400/2787 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/decomposition/_pca.py:648: RuntimeWarning: invalid value encountered in divide\n",
            "  explained_variance_ratio_ = explained_variance_ / total_var\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 500/2787 windows...\n",
            "  Processed 600/2787 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n",
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 700/2787 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 800/2787 windows...\n",
            "  Processed 900/2787 windows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3737695984.py:29: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'skew': skew(sig),\n",
            "/tmp/ipython-input-3737695984.py:30: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
            "  'kurt': kurtosis(sig),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 1000/2787 windows...\n",
            "  Processed 1100/2787 windows...\n",
            "  Processed 1200/2787 windows...\n",
            "  Processed 1300/2787 windows...\n",
            "  Processed 1400/2787 windows...\n",
            "  Processed 1500/2787 windows...\n",
            "  Processed 1600/2787 windows...\n",
            "  Processed 1700/2787 windows...\n",
            "  Processed 1800/2787 windows...\n",
            "  Processed 1900/2787 windows...\n",
            "  Processed 2000/2787 windows...\n",
            "  Processed 2100/2787 windows...\n",
            "  Processed 2200/2787 windows...\n",
            "  Processed 2300/2787 windows...\n",
            "  Processed 2400/2787 windows...\n",
            "  Processed 2500/2787 windows...\n",
            "  Processed 2600/2787 windows...\n",
            "  Processed 2700/2787 windows...\n",
            "\n",
            " Feature extraction complete!\n",
            "   Feature matrix shape: (2787, 206)\n",
            "   Total features: 206\n",
            "   Label distribution: Walk=1038, FoG=1038, Transition=711\n",
            "\n",
            "============================================================\n",
            "SAMPLE FEATURES (first 20 columns):\n",
            "============================================================\n",
            "['x_mean', 'x_std', 'x_min', 'x_max', 'x_q1', 'x_median', 'x_q3', 'x_skew', 'x_kurt', 'x_zero_cross', 'x_ptp', 'x_crest_factor', 'x_rms', 'x_vel_rms', 'x_entropy', 'x_freeze_index', 'x_power_diff', 'x_total_power', 'x_power_band_05_3', 'x_power_band_3_8']\n",
            "\n",
            "Total feature count: 206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from boruta import BorutaPy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def prepare_dataset_with_feature_selection(X, y, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Proper pipeline:\n",
        "    1. Stratified train/test split\n",
        "    2. Feature selection on training data only\n",
        "    3. Apply to both train and test\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"PREPARING DATASET WITH FEATURE SELECTION\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # ===== STEP 1: STRATIFIED TRAIN/TEST SPLIT =====\n",
        "    print(f\"\\n1. Splitting data (80/20 with stratification)...\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y,\n",
        "        test_size=test_size,\n",
        "        stratify=y,  # CRITICAL: Ensures all classes in both sets\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    print(f\"   Train set: {X_train.shape} - Labels: {np.bincount(y_train)}\")\n",
        "    print(f\"   Test set:  {X_test.shape} - Labels: {np.bincount(y_test)}\")\n",
        "\n",
        "    # Check if all classes present in test set\n",
        "    unique_test_classes = np.unique(y_test)\n",
        "    if len(unique_test_classes) != 3:\n",
        "        print(f\"    WARNING: Test set missing classes! Only has: {unique_test_classes}\")\n",
        "\n",
        "    # ===== STEP 2: STANDARDIZE FEATURES =====\n",
        "    print(f\"\\n2. Standardizing features...\")\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)  # Use training statistics!\n",
        "\n",
        "    # ===== STEP 3: BORUTA FEATURE SELECTION (on training data only) =====\n",
        "    print(f\"\\n3. Running Boruta feature selection (this may take a while)...\")\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        n_jobs=-1,\n",
        "        class_weight='balanced',\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    boruta_selector = BorutaPy(\n",
        "        rf,\n",
        "        n_estimators='auto',\n",
        "        verbose=1,\n",
        "        random_state=random_state,\n",
        "        max_iter=50\n",
        "    )\n",
        "\n",
        "    # CRITICAL: Fit only on training data!\n",
        "    boruta_selector.fit(X_train_scaled, y_train)\n",
        "\n",
        "    selected_features = boruta_selector.support_\n",
        "    selected_feature_names = X.columns[selected_features].tolist()\n",
        "\n",
        "    print(f\"    Boruta selected {len(selected_feature_names)} features\")\n",
        "\n",
        "    # Apply selection to both train and test\n",
        "    X_train_boruta = X_train_scaled[:, selected_features]\n",
        "    X_test_boruta = X_test_scaled[:, selected_features]\n",
        "\n",
        "    # ===== STEP 4: GRADIENT BOOSTING  Top 30 Features =====\n",
        "    print(f\"\\n4. Gradient Boosting feature importance (top 30)...\")\n",
        "    gbm = GradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    gbm.fit(X_train_boruta, y_train)\n",
        "\n",
        "    # Get feature importances\n",
        "    feature_importances = gbm.feature_importances_\n",
        "    top_30_indices = np.argsort(feature_importances)[-30:][::-1]\n",
        "    top_30_features = [selected_feature_names[i] for i in top_30_indices]\n",
        "\n",
        "    X_train_30 = X_train_boruta[:, top_30_indices]\n",
        "    X_test_30 = X_test_boruta[:, top_30_indices]\n",
        "\n",
        "    print(f\"    Top 30 features selected\")\n",
        "    print(f\"   Top 5: {top_30_features[:5]}\")\n",
        "\n",
        "    # ===== STEP 5: XGBoost  Top 15 Features =====\n",
        "    print(f\"\\n5. XGBoost feature importance (top 15)...\")\n",
        "    xgb = XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        random_state=random_state,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "    xgb.fit(X_train_30, y_train)\n",
        "\n",
        "    feature_importances_xgb = xgb.feature_importances_\n",
        "    top_15_indices = np.argsort(feature_importances_xgb)[-15:][::-1]\n",
        "    top_15_features = [top_30_features[i] for i in top_15_indices]\n",
        "\n",
        "    X_train_15 = X_train_30[:, top_15_indices]\n",
        "    X_test_15 = X_test_30[:, top_15_indices]\n",
        "\n",
        "    print(f\"    Top 15 features selected\")\n",
        "    print(f\"   Features: {top_15_features}\")\n",
        "\n",
        "    # ===== STEP 6: XGBoost  Top 5 Features =====\n",
        "    print(f\"\\n6. XGBoost final selection (top 5)...\")\n",
        "    xgb2 = XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        random_state=random_state,\n",
        "        eval_metric='mlogloss'\n",
        "    )\n",
        "    xgb2.fit(X_train_15, y_train)\n",
        "\n",
        "    feature_importances_xgb2 = xgb2.feature_importances_\n",
        "    top_5_indices = np.argsort(feature_importances_xgb2)[-5:][::-1]\n",
        "    top_5_features = [top_15_features[i] for i in top_5_indices]\n",
        "\n",
        "    X_train_5 = X_train_15[:, top_5_indices]\n",
        "    X_test_5 = X_test_15[:, top_5_indices]\n",
        "\n",
        "    print(f\"    Top 5 features selected\")\n",
        "    print(f\"   Features: {top_5_features}\")\n",
        "\n",
        "    # ===== RETURN ALL FEATURE SETS =====\n",
        "    return {\n",
        "        'train': {\n",
        "            'all': (X_train_scaled, y_train),\n",
        "            'boruta': (X_train_boruta, y_train),\n",
        "            '30': (X_train_30, y_train),\n",
        "            '15': (X_train_15, y_train),\n",
        "            '5': (X_train_5, y_train)\n",
        "        },\n",
        "        'test': {\n",
        "            'all': (X_test_scaled, y_test),\n",
        "            'boruta': (X_test_boruta, y_test),\n",
        "            '30': (X_test_30, y_test),\n",
        "            '15': (X_test_15, y_test),\n",
        "            '5': (X_test_5, y_test)\n",
        "        },\n",
        "        'feature_names': {\n",
        "            'boruta': selected_feature_names,\n",
        "            '30': top_30_features,\n",
        "            '15': top_15_features,\n",
        "            '5': top_5_features\n",
        "        },\n",
        "        'scaler': scaler\n",
        "    }\n",
        "\n",
        "# ===== PREPARE ALL THREE DATASETS =====\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATASET A: 2s WINDOWS\")\n",
        "print(\"=\"*70)\n",
        "data_2s = prepare_dataset_with_feature_selection(X_2s, y_2s)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATASET B: 3s WINDOWS\")\n",
        "print(\"=\"*70)\n",
        "data_3s = prepare_dataset_with_feature_selection(X_3s, y_3s)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATASET C: 4s WINDOWS\")\n",
        "print(\"=\"*70)\n",
        "data_4s = prepare_dataset_with_feature_selection(X_4s, y_4s)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" ALL DATASETS PREPARED!\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmDqp3zBdEiT",
        "outputId": "85ec0805-1ca8-41dc-9500-cf6d4f606bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "DATASET A: 2s WINDOWS\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "PREPARING DATASET WITH FEATURE SELECTION\n",
            "============================================================\n",
            "\n",
            "1. Splitting data (80/20 with stratification)...\n",
            "   Train set: (3854, 206) - Labels: [2148 1137  569]\n",
            "   Test set:  (964, 206) - Labels: [537 285 142]\n",
            "\n",
            "2. Standardizing features...\n",
            "\n",
            "3. Running Boruta feature selection (this may take a while)...\n",
            "Iteration: 1 / 50\n",
            "Iteration: 2 / 50\n",
            "Iteration: 3 / 50\n",
            "Iteration: 4 / 50\n",
            "Iteration: 5 / 50\n",
            "Iteration: 6 / 50\n",
            "Iteration: 7 / 50\n",
            "Iteration: 8 / 50\n",
            "Iteration: 9 / 50\n",
            "Iteration: 10 / 50\n",
            "Iteration: 11 / 50\n",
            "Iteration: 12 / 50\n",
            "Iteration: 13 / 50\n",
            "Iteration: 14 / 50\n",
            "Iteration: 15 / 50\n",
            "Iteration: 16 / 50\n",
            "Iteration: 17 / 50\n",
            "Iteration: 18 / 50\n",
            "Iteration: 19 / 50\n",
            "Iteration: 20 / 50\n",
            "Iteration: 21 / 50\n",
            "Iteration: 22 / 50\n",
            "Iteration: 23 / 50\n",
            "Iteration: 24 / 50\n",
            "Iteration: 25 / 50\n",
            "Iteration: 26 / 50\n",
            "Iteration: 27 / 50\n",
            "Iteration: 28 / 50\n",
            "Iteration: 29 / 50\n",
            "Iteration: 30 / 50\n",
            "Iteration: 31 / 50\n",
            "Iteration: 32 / 50\n",
            "Iteration: 33 / 50\n",
            "Iteration: 34 / 50\n",
            "Iteration: 35 / 50\n",
            "Iteration: 36 / 50\n",
            "Iteration: 37 / 50\n",
            "Iteration: 38 / 50\n",
            "Iteration: 39 / 50\n",
            "Iteration: 40 / 50\n",
            "Iteration: 41 / 50\n",
            "Iteration: 42 / 50\n",
            "Iteration: 43 / 50\n",
            "Iteration: 44 / 50\n",
            "Iteration: 45 / 50\n",
            "Iteration: 46 / 50\n",
            "Iteration: 47 / 50\n",
            "Iteration: 48 / 50\n",
            "Iteration: 49 / 50\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t50 / 50\n",
            "Confirmed: \t152\n",
            "Tentative: \t20\n",
            "Rejected: \t34\n",
            "    Boruta selected 152 features\n",
            "\n",
            "4. Gradient Boosting feature importance (top 30)...\n",
            "    Top 30 features selected\n",
            "   Top 5: ['x_power_diff', 'mag_power_diff', 'mag_kurt', 'x_max', 'y_power_diff']\n",
            "\n",
            "5. XGBoost feature importance (top 15)...\n",
            "    Top 15 features selected\n",
            "   Features: ['x_power_diff', 'mag_power_diff', 'mag_kurt', 'pc2_power_diff', 'z_median', 'x_max', 'y_power_diff', 'x_median', 'integral_y', 'mag_fft_coef_2', 'y_kurt', 'x_q3', 'x_q1', 'z_q1', 'x_dom_freq']\n",
            "\n",
            "6. XGBoost final selection (top 5)...\n",
            "    Top 5 features selected\n",
            "   Features: ['x_power_diff', 'mag_power_diff', 'mag_kurt', 'z_median', 'x_dom_freq']\n",
            "\n",
            "======================================================================\n",
            "DATASET B: 3s WINDOWS\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "PREPARING DATASET WITH FEATURE SELECTION\n",
            "============================================================\n",
            "\n",
            "1. Splitting data (80/20 with stratification)...\n",
            "   Train set: (2968, 206) - Labels: [1261 1138  569]\n",
            "   Test set:  (742, 206) - Labels: [316 284 142]\n",
            "\n",
            "2. Standardizing features...\n",
            "\n",
            "3. Running Boruta feature selection (this may take a while)...\n",
            "Iteration: 1 / 50\n",
            "Iteration: 2 / 50\n",
            "Iteration: 3 / 50\n",
            "Iteration: 4 / 50\n",
            "Iteration: 5 / 50\n",
            "Iteration: 6 / 50\n",
            "Iteration: 7 / 50\n",
            "Iteration: 8 / 50\n",
            "Iteration: 9 / 50\n",
            "Iteration: 10 / 50\n",
            "Iteration: 11 / 50\n",
            "Iteration: 12 / 50\n",
            "Iteration: 13 / 50\n",
            "Iteration: 14 / 50\n",
            "Iteration: 15 / 50\n",
            "Iteration: 16 / 50\n",
            "Iteration: 17 / 50\n",
            "Iteration: 18 / 50\n",
            "Iteration: 19 / 50\n",
            "Iteration: 20 / 50\n",
            "Iteration: 21 / 50\n",
            "Iteration: 22 / 50\n",
            "Iteration: 23 / 50\n",
            "Iteration: 24 / 50\n",
            "Iteration: 25 / 50\n",
            "Iteration: 26 / 50\n",
            "Iteration: 27 / 50\n",
            "Iteration: 28 / 50\n",
            "Iteration: 29 / 50\n",
            "Iteration: 30 / 50\n",
            "Iteration: 31 / 50\n",
            "Iteration: 32 / 50\n",
            "Iteration: 33 / 50\n",
            "Iteration: 34 / 50\n",
            "Iteration: 35 / 50\n",
            "Iteration: 36 / 50\n",
            "Iteration: 37 / 50\n",
            "Iteration: 38 / 50\n",
            "Iteration: 39 / 50\n",
            "Iteration: 40 / 50\n",
            "Iteration: 41 / 50\n",
            "Iteration: 42 / 50\n",
            "Iteration: 43 / 50\n",
            "Iteration: 44 / 50\n",
            "Iteration: 45 / 50\n",
            "Iteration: 46 / 50\n",
            "Iteration: 47 / 50\n",
            "Iteration: 48 / 50\n",
            "Iteration: 49 / 50\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t50 / 50\n",
            "Confirmed: \t165\n",
            "Tentative: \t18\n",
            "Rejected: \t23\n",
            "    Boruta selected 165 features\n",
            "\n",
            "4. Gradient Boosting feature importance (top 30)...\n",
            "    Top 30 features selected\n",
            "   Top 5: ['x_power_diff', 'y_power_diff', 'pc1_crest_factor', 'x_max', 'mag_power_diff']\n",
            "\n",
            "5. XGBoost feature importance (top 15)...\n",
            "    Top 15 features selected\n",
            "   Features: ['x_power_diff', 'y_power_diff', 'pc1_crest_factor', 'z_fft_coef_2', 'mag_power_diff', 'x_max', 'pc2_power_diff', 'integral_y', 'z_power_band_05_3', 'z_mean', 'pc3_total_power', 'y_median', 'z_median', 'z_freeze_index', 'z_dom_freq']\n",
            "\n",
            "6. XGBoost final selection (top 5)...\n",
            "    Top 5 features selected\n",
            "   Features: ['x_power_diff', 'y_power_diff', 'pc1_crest_factor', 'x_max', 'z_fft_coef_2']\n",
            "\n",
            "======================================================================\n",
            "DATASET C: 4s WINDOWS\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "PREPARING DATASET WITH FEATURE SELECTION\n",
            "============================================================\n",
            "\n",
            "1. Splitting data (80/20 with stratification)...\n",
            "   Train set: (2229, 206) - Labels: [830 830 569]\n",
            "   Test set:  (558, 206) - Labels: [208 208 142]\n",
            "\n",
            "2. Standardizing features...\n",
            "\n",
            "3. Running Boruta feature selection (this may take a while)...\n",
            "Iteration: 1 / 50\n",
            "Iteration: 2 / 50\n",
            "Iteration: 3 / 50\n",
            "Iteration: 4 / 50\n",
            "Iteration: 5 / 50\n",
            "Iteration: 6 / 50\n",
            "Iteration: 7 / 50\n",
            "Iteration: 8 / 50\n",
            "Iteration: 9 / 50\n",
            "Iteration: 10 / 50\n",
            "Iteration: 11 / 50\n",
            "Iteration: 12 / 50\n",
            "Iteration: 13 / 50\n",
            "Iteration: 14 / 50\n",
            "Iteration: 15 / 50\n",
            "Iteration: 16 / 50\n",
            "Iteration: 17 / 50\n",
            "Iteration: 18 / 50\n",
            "Iteration: 19 / 50\n",
            "Iteration: 20 / 50\n",
            "Iteration: 21 / 50\n",
            "Iteration: 22 / 50\n",
            "Iteration: 23 / 50\n",
            "Iteration: 24 / 50\n",
            "Iteration: 25 / 50\n",
            "Iteration: 26 / 50\n",
            "Iteration: 27 / 50\n",
            "Iteration: 28 / 50\n",
            "Iteration: 29 / 50\n",
            "Iteration: 30 / 50\n",
            "Iteration: 31 / 50\n",
            "Iteration: 32 / 50\n",
            "Iteration: 33 / 50\n",
            "Iteration: 34 / 50\n",
            "Iteration: 35 / 50\n",
            "Iteration: 36 / 50\n",
            "Iteration: 37 / 50\n",
            "Iteration: 38 / 50\n",
            "Iteration: 39 / 50\n",
            "Iteration: 40 / 50\n",
            "Iteration: 41 / 50\n",
            "Iteration: 42 / 50\n",
            "Iteration: 43 / 50\n",
            "Iteration: 44 / 50\n",
            "Iteration: 45 / 50\n",
            "Iteration: 46 / 50\n",
            "Iteration: 47 / 50\n",
            "Iteration: 48 / 50\n",
            "Iteration: 49 / 50\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t50 / 50\n",
            "Confirmed: \t156\n",
            "Tentative: \t21\n",
            "Rejected: \t29\n",
            "    Boruta selected 156 features\n",
            "\n",
            "4. Gradient Boosting feature importance (top 30)...\n",
            "    Top 30 features selected\n",
            "   Top 5: ['x_power_diff', 'mag_power_diff', 'y_power_diff', 'z_power_band_05_3', 'pc1_crest_factor']\n",
            "\n",
            "5. XGBoost feature importance (top 15)...\n",
            "    Top 15 features selected\n",
            "   Features: ['mag_power_diff', 'x_power_diff', 'y_power_diff', 'z_power_band_05_3', 'pc1_crest_factor', 'integral_y', 'y_mean', 'z_mean', 'x_max', 'y_median', 'mag_q1', 'pc1_zero_cross', 'pc2_q3', 'z_freeze_index', 'pc2_power_diff']\n",
            "\n",
            "6. XGBoost final selection (top 5)...\n",
            "    Top 5 features selected\n",
            "   Features: ['x_power_diff', 'mag_power_diff', 'y_power_diff', 'z_power_band_05_3', 'integral_y']\n",
            "\n",
            "======================================================================\n",
            " ALL DATASETS PREPARED!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def compute_per_class_metrics(y_true, y_pred, class_names=['Walk', 'FoG', 'Transition']):\n",
        "    \"\"\"\n",
        "    Compute sensitivity and specificity for each class.\n",
        "\n",
        "    Sensitivity = TP / (TP + FN) = Recall\n",
        "    Specificity = TN / (TN + FP)\n",
        "    \"\"\"\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    n_classes = len(class_names)\n",
        "\n",
        "    metrics = {}\n",
        "\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        # For class i:\n",
        "        TP = cm[i, i]\n",
        "        FN = cm[i, :].sum() - TP\n",
        "        FP = cm[:, i].sum() - TP\n",
        "        TN = cm.sum() - TP - FN - FP\n",
        "\n",
        "        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "\n",
        "        metrics[class_name] = {\n",
        "            'sensitivity': sensitivity * 100,\n",
        "            'specificity': specificity * 100,\n",
        "            'TP': TP,\n",
        "            'FN': FN,\n",
        "            'FP': FP,\n",
        "            'TN': TN\n",
        "        }\n",
        "\n",
        "    return metrics, cm\n",
        "\n",
        "def train_and_evaluate_model(model, model_name, X_train, y_train, X_test, y_test, cv_folds=10):\n",
        "    \"\"\"\n",
        "    Train model with 10-fold CV on training set, then evaluate on test set.\n",
        "    Returns per-class sensitivity and specificity.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # ===== 10-FOLD CROSS-VALIDATION ON TRAINING SET =====\n",
        "    print(f\"Performing {cv_folds}-fold cross-validation on training set...\")\n",
        "    skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='accuracy')\n",
        "\n",
        "    print(f\"CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
        "\n",
        "    # ===== TRAIN ON FULL TRAINING SET =====\n",
        "    print(f\"Training on full training set...\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # ===== EVALUATE ON TEST SET =====\n",
        "    print(f\"\\nEvaluating on test set...\")\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "    # ===== COMPUTE PER-CLASS METRICS =====\n",
        "    metrics, cm = compute_per_class_metrics(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(f\"\\n{'Class':<12} {'Sensitivity':<15} {'Specificity':<15}\")\n",
        "    print(\"-\" * 42)\n",
        "    for class_name, vals in metrics.items():\n",
        "        print(f\"{class_name:<12} {vals['sensitivity']:>6.2f}%{'':<8} {vals['specificity']:>6.2f}%\")\n",
        "\n",
        "    # ===== DETAILED CLASSIFICATION REPORT =====\n",
        "    print(f\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Walk', 'FoG', 'Transition']))\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'cv_accuracy': cv_scores.mean(),\n",
        "        'test_accuracy': test_accuracy,\n",
        "        'metrics': metrics,\n",
        "        'confusion_matrix': cm,\n",
        "        'predictions': y_pred\n",
        "    }\n",
        "\n",
        "def evaluate_all_models(data_dict, dataset_name, feature_set='30'):\n",
        "    \"\"\"\n",
        "    Evaluate all 5 models on a specific dataset and feature set.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'#'*70}\")\n",
        "    print(f\"# EVALUATING {dataset_name} - {feature_set} FEATURES\")\n",
        "    print(f\"{'#'*70}\")\n",
        "\n",
        "    X_train, y_train = data_dict['train'][feature_set]\n",
        "    X_test, y_test = data_dict['test'][feature_set]\n",
        "\n",
        "    print(f\"\\nDataset info:\")\n",
        "    print(f\"  Training samples: {len(y_train)} (Walk={np.sum(y_train==0)}, FoG={np.sum(y_train==1)}, Trans={np.sum(y_train==2)})\")\n",
        "    print(f\"  Test samples: {len(y_test)} (Walk={np.sum(y_test==0)}, FoG={np.sum(y_test==1)}, Trans={np.sum(y_test==2)})\")\n",
        "\n",
        "    # ===== DEFINE MODELS =====\n",
        "    models = {\n",
        "        'Random Forest': RandomForestClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=10,\n",
        "            class_weight='balanced',\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        ),\n",
        "        'XGBoost': XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=5,\n",
        "            learning_rate=0.1,\n",
        "            random_state=42,\n",
        "            eval_metric='mlogloss',\n",
        "            n_jobs=-1\n",
        "        ),\n",
        "        'Gradient Boosting': GradientBoostingClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=5,\n",
        "            learning_rate=0.1,\n",
        "            random_state=42\n",
        "        ),\n",
        "        'RBF-SVM': SVC(\n",
        "            kernel='rbf',\n",
        "            C=1.0,\n",
        "            gamma='scale',\n",
        "            class_weight='balanced',\n",
        "            random_state=42\n",
        "        ),\n",
        "        'MLP': MLPClassifier(\n",
        "            hidden_layer_sizes=(100, 50),\n",
        "            activation='relu',\n",
        "            solver='adam',\n",
        "            max_iter=500,\n",
        "            random_state=42,\n",
        "            early_stopping=True\n",
        "        )\n",
        "    }\n",
        "\n",
        "    # ===== TRAIN AND EVALUATE EACH MODEL =====\n",
        "    results = {}\n",
        "    for model_name, model in models.items():\n",
        "        results[model_name] = train_and_evaluate_model(\n",
        "            model, model_name, X_train, y_train, X_test, y_test\n",
        "        )\n",
        "\n",
        "    # ===== SUMMARY TABLE =====\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"SUMMARY: {dataset_name} - {feature_set} FEATURES\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"\\n{'Model':<20} {'Accuracy':<12} {'Walk Sens':<12} {'FoG Sens':<12} {'Trans Sens':<12}\")\n",
        "    print(\"-\" * 68)\n",
        "    for model_name, result in results.items():\n",
        "        metrics = result['metrics']\n",
        "        print(f\"{model_name:<20} {result['test_accuracy']*100:>6.2f}%{'':<5} \"\n",
        "              f\"{metrics['Walk']['sensitivity']:>6.2f}%{'':<5} \"\n",
        "              f\"{metrics['FoG']['sensitivity']:>6.2f}%{'':<5} \"\n",
        "              f\"{metrics['Transition']['sensitivity']:>6.2f}%\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# ===== RUN EVALUATIONS =====\n",
        "# You can run all combinations or select specific ones\n",
        "\n",
        "# Example: Evaluate 2s dataset with 5 features\n",
        "results_2s_5feat = evaluate_all_models(data_2s, \"2s Dataset\", feature_set='5')\n",
        "\n",
        "# Example: Evaluate 3s dataset with 15 features\n",
        "results_3s_15feat = evaluate_all_models(data_3s, \"3s Dataset\", feature_set='15')\n",
        "\n",
        "# Example: Evaluate 4s dataset with 30 features\n",
        "results_4s_30feat = evaluate_all_models(data_4s, \"4s Dataset\", feature_set='30')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua4OXOsQeJMR",
        "outputId": "146db688-a243-4bcc-db5d-c3c5c9d59247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "######################################################################\n",
            "# EVALUATING 2s Dataset - 5 FEATURES\n",
            "######################################################################\n",
            "\n",
            "Dataset info:\n",
            "  Training samples: 3854 (Walk=2148, FoG=1137, Trans=569)\n",
            "  Test samples: 964 (Walk=537, FoG=285, Trans=142)\n",
            "\n",
            "============================================================\n",
            "Training Random Forest\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7250 (+/- 0.0207)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7116 (71.16%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[425  59  53]\n",
            " [ 23 207  55]\n",
            " [ 28  60  54]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          79.14%          88.06%\n",
            "FoG           72.63%          82.47%\n",
            "Transition    38.03%          86.86%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.89      0.79      0.84       537\n",
            "         FoG       0.63      0.73      0.68       285\n",
            "  Transition       0.33      0.38      0.36       142\n",
            "\n",
            "    accuracy                           0.71       964\n",
            "   macro avg       0.62      0.63      0.62       964\n",
            "weighted avg       0.73      0.71      0.72       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training XGBoost\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7314 (+/- 0.0094)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7479 (74.79%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[454  64  19]\n",
            " [ 37 241   7]\n",
            " [ 36  80  26]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.54%          82.90%\n",
            "FoG           84.56%          78.79%\n",
            "Transition    18.31%          96.84%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.86      0.85      0.85       537\n",
            "         FoG       0.63      0.85      0.72       285\n",
            "  Transition       0.50      0.18      0.27       142\n",
            "\n",
            "    accuracy                           0.75       964\n",
            "   macro avg       0.66      0.62      0.61       964\n",
            "weighted avg       0.74      0.75      0.73       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training Gradient Boosting\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7265 (+/- 0.0161)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7438 (74.38%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[458  56  23]\n",
            " [ 42 227  16]\n",
            " [ 39  71  32]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          85.29%          81.03%\n",
            "FoG           79.65%          81.30%\n",
            "Transition    22.54%          95.26%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.85      0.85      0.85       537\n",
            "         FoG       0.64      0.80      0.71       285\n",
            "  Transition       0.45      0.23      0.30       142\n",
            "\n",
            "    accuracy                           0.74       964\n",
            "   macro avg       0.65      0.62      0.62       964\n",
            "weighted avg       0.73      0.74      0.73       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training RBF-SVM\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.6482 (+/- 0.0194)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.6234 (62.34%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[393  43 101]\n",
            " [ 41 143 101]\n",
            " [ 21  56  65]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          73.18%          85.48%\n",
            "FoG           50.18%          85.42%\n",
            "Transition    45.77%          75.43%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.86      0.73      0.79       537\n",
            "         FoG       0.59      0.50      0.54       285\n",
            "  Transition       0.24      0.46      0.32       142\n",
            "\n",
            "    accuracy                           0.62       964\n",
            "   macro avg       0.57      0.56      0.55       964\n",
            "weighted avg       0.69      0.62      0.65       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training MLP\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7026 (+/- 0.0120)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7085 (70.85%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[454  82   1]\n",
            " [ 59 223   3]\n",
            " [ 46  90   6]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.54%          75.41%\n",
            "FoG           78.25%          74.67%\n",
            "Transition     4.23%          99.51%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.81      0.85      0.83       537\n",
            "         FoG       0.56      0.78      0.66       285\n",
            "  Transition       0.60      0.04      0.08       142\n",
            "\n",
            "    accuracy                           0.71       964\n",
            "   macro avg       0.66      0.56      0.52       964\n",
            "weighted avg       0.71      0.71      0.67       964\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: 2s Dataset - 5 FEATURES\n",
            "======================================================================\n",
            "\n",
            "Model                Accuracy     Walk Sens    FoG Sens     Trans Sens  \n",
            "--------------------------------------------------------------------\n",
            "Random Forest         71.16%       79.14%       72.63%       38.03%\n",
            "XGBoost               74.79%       84.54%       84.56%       18.31%\n",
            "Gradient Boosting     74.38%       85.29%       79.65%       22.54%\n",
            "RBF-SVM               62.34%       73.18%       50.18%       45.77%\n",
            "MLP                   70.85%       84.54%       78.25%        4.23%\n",
            "\n",
            "######################################################################\n",
            "# EVALUATING 3s Dataset - 15 FEATURES\n",
            "######################################################################\n",
            "\n",
            "Dataset info:\n",
            "  Training samples: 2968 (Walk=1261, FoG=1138, Trans=569)\n",
            "  Test samples: 742 (Walk=316, FoG=284, Trans=142)\n",
            "\n",
            "============================================================\n",
            "Training Random Forest\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7736 (+/- 0.0324)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7547 (75.47%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[255  26  35]\n",
            " [ 13 231  40]\n",
            " [ 23  45  74]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          80.70%          91.55%\n",
            "FoG           81.34%          84.50%\n",
            "Transition    52.11%          87.50%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.88      0.81      0.84       316\n",
            "         FoG       0.76      0.81      0.79       284\n",
            "  Transition       0.50      0.52      0.51       142\n",
            "\n",
            "    accuracy                           0.75       742\n",
            "   macro avg       0.71      0.71      0.71       742\n",
            "weighted avg       0.76      0.75      0.76       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training XGBoost\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7847 (+/- 0.0305)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7776 (77.76%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[264  26  26]\n",
            " [ 12 246  26]\n",
            " [ 26  49  67]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          83.54%          91.08%\n",
            "FoG           86.62%          83.62%\n",
            "Transition    47.18%          91.33%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.87      0.84      0.85       316\n",
            "         FoG       0.77      0.87      0.81       284\n",
            "  Transition       0.56      0.47      0.51       142\n",
            "\n",
            "    accuracy                           0.78       742\n",
            "   macro avg       0.73      0.72      0.73       742\n",
            "weighted avg       0.77      0.78      0.77       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training Gradient Boosting\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7810 (+/- 0.0289)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7817 (78.17%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[266  25  25]\n",
            " [ 13 248  23]\n",
            " [ 28  48  66]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.18%          90.38%\n",
            "FoG           87.32%          84.06%\n",
            "Transition    46.48%          92.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.87      0.84      0.85       316\n",
            "         FoG       0.77      0.87      0.82       284\n",
            "  Transition       0.58      0.46      0.52       142\n",
            "\n",
            "    accuracy                           0.78       742\n",
            "   macro avg       0.74      0.73      0.73       742\n",
            "weighted avg       0.78      0.78      0.78       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training RBF-SVM\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7156 (+/- 0.0363)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.6873 (68.73%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[221  32  63]\n",
            " [ 27 203  54]\n",
            " [ 15  41  86]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          69.94%          90.14%\n",
            "FoG           71.48%          84.06%\n",
            "Transition    60.56%          80.50%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.84      0.70      0.76       316\n",
            "         FoG       0.74      0.71      0.72       284\n",
            "  Transition       0.42      0.61      0.50       142\n",
            "\n",
            "    accuracy                           0.69       742\n",
            "   macro avg       0.67      0.67      0.66       742\n",
            "weighted avg       0.72      0.69      0.70       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training MLP\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7140 (+/- 0.0277)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7197 (71.97%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[238  47  31]\n",
            " [ 20 236  28]\n",
            " [ 27  55  60]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          75.32%          88.97%\n",
            "FoG           83.10%          77.73%\n",
            "Transition    42.25%          90.17%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.84      0.75      0.79       316\n",
            "         FoG       0.70      0.83      0.76       284\n",
            "  Transition       0.50      0.42      0.46       142\n",
            "\n",
            "    accuracy                           0.72       742\n",
            "   macro avg       0.68      0.67      0.67       742\n",
            "weighted avg       0.72      0.72      0.72       742\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: 3s Dataset - 15 FEATURES\n",
            "======================================================================\n",
            "\n",
            "Model                Accuracy     Walk Sens    FoG Sens     Trans Sens  \n",
            "--------------------------------------------------------------------\n",
            "Random Forest         75.47%       80.70%       81.34%       52.11%\n",
            "XGBoost               77.76%       83.54%       86.62%       47.18%\n",
            "Gradient Boosting     78.17%       84.18%       87.32%       46.48%\n",
            "RBF-SVM               68.73%       69.94%       71.48%       60.56%\n",
            "MLP                   71.97%       75.32%       83.10%       42.25%\n",
            "\n",
            "######################################################################\n",
            "# EVALUATING 4s Dataset - 30 FEATURES\n",
            "######################################################################\n",
            "\n",
            "Dataset info:\n",
            "  Training samples: 2229 (Walk=830, FoG=830, Trans=569)\n",
            "  Test samples: 558 (Walk=208, FoG=208, Trans=142)\n",
            "\n",
            "============================================================\n",
            "Training Random Forest\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7860 (+/- 0.0220)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.8082 (80.82%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[173  14  21]\n",
            " [  4 185  19]\n",
            " [ 24  25  93]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          83.17%          92.00%\n",
            "FoG           88.94%          88.86%\n",
            "Transition    65.49%          90.38%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.86      0.83      0.85       208\n",
            "         FoG       0.83      0.89      0.86       208\n",
            "  Transition       0.70      0.65      0.68       142\n",
            "\n",
            "    accuracy                           0.81       558\n",
            "   macro avg       0.80      0.79      0.79       558\n",
            "weighted avg       0.81      0.81      0.81       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training XGBoost\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.8030 (+/- 0.0209)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.8118 (81.18%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[174  14  20]\n",
            " [  3 185  20]\n",
            " [ 25  23  94]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          83.65%          92.00%\n",
            "FoG           88.94%          89.43%\n",
            "Transition    66.20%          90.38%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.86      0.84      0.85       208\n",
            "         FoG       0.83      0.89      0.86       208\n",
            "  Transition       0.70      0.66      0.68       142\n",
            "\n",
            "    accuracy                           0.81       558\n",
            "   macro avg       0.80      0.80      0.80       558\n",
            "weighted avg       0.81      0.81      0.81       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training Gradient Boosting\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7999 (+/- 0.0215)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.8190 (81.90%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[179  11  18]\n",
            " [  4 184  20]\n",
            " [ 24  24  94]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          86.06%          92.00%\n",
            "FoG           88.46%          90.00%\n",
            "Transition    66.20%          90.87%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.86      0.86      0.86       208\n",
            "         FoG       0.84      0.88      0.86       208\n",
            "  Transition       0.71      0.66      0.69       142\n",
            "\n",
            "    accuracy                           0.82       558\n",
            "   macro avg       0.81      0.80      0.80       558\n",
            "weighted avg       0.82      0.82      0.82       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training RBF-SVM\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7487 (+/- 0.0321)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7885 (78.85%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[162  17  29]\n",
            " [  9 177  22]\n",
            " [ 21  20 101]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          77.88%          91.43%\n",
            "FoG           85.10%          89.43%\n",
            "Transition    71.13%          87.74%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.84      0.78      0.81       208\n",
            "         FoG       0.83      0.85      0.84       208\n",
            "  Transition       0.66      0.71      0.69       142\n",
            "\n",
            "    accuracy                           0.79       558\n",
            "   macro avg       0.78      0.78      0.78       558\n",
            "weighted avg       0.79      0.79      0.79       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training MLP\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7470 (+/- 0.0202)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7760 (77.60%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[177  20  11]\n",
            " [  7 179  22]\n",
            " [ 37  28  77]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          85.10%          87.43%\n",
            "FoG           86.06%          86.29%\n",
            "Transition    54.23%          92.07%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.80      0.85      0.83       208\n",
            "         FoG       0.79      0.86      0.82       208\n",
            "  Transition       0.70      0.54      0.61       142\n",
            "\n",
            "    accuracy                           0.78       558\n",
            "   macro avg       0.76      0.75      0.75       558\n",
            "weighted avg       0.77      0.78      0.77       558\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: 4s Dataset - 30 FEATURES\n",
            "======================================================================\n",
            "\n",
            "Model                Accuracy     Walk Sens    FoG Sens     Trans Sens  \n",
            "--------------------------------------------------------------------\n",
            "Random Forest         80.82%       83.17%       88.94%       65.49%\n",
            "XGBoost               81.18%       83.65%       88.94%       66.20%\n",
            "Gradient Boosting     81.90%       86.06%       88.46%       66.20%\n",
            "RBF-SVM               78.85%       77.88%       85.10%       71.13%\n",
            "MLP                   77.60%       85.10%       86.06%       54.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test all 9 combinations (3 datasets  3 feature sets)\n",
        "combinations = [\n",
        "    (data_2s, '2s', '5'), (data_2s, '2s', '15'), (data_2s, '2s', '30'),\n",
        "    (data_3s, '3s', '5'), (data_3s, '3s', '15'), (data_3s, '3s', '30'),\n",
        "    (data_4s, '4s', '5'), (data_4s, '4s', '15'), (data_4s, '4s', '30'),\n",
        "]\n",
        "\n",
        "all_results = {}\n",
        "for data, name, feat in combinations:\n",
        "    all_results[f\"{name}_{feat}\"] = evaluate_all_models(data, name, feat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHsgZMNyfRjS",
        "outputId": "9f7814fa-a43d-4905-f6e2-630ed2ed0467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "######################################################################\n",
            "# EVALUATING 2s - 5 FEATURES\n",
            "######################################################################\n",
            "\n",
            "Dataset info:\n",
            "  Training samples: 3854 (Walk=2148, FoG=1137, Trans=569)\n",
            "  Test samples: 964 (Walk=537, FoG=285, Trans=142)\n",
            "\n",
            "============================================================\n",
            "Training Random Forest\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7250 (+/- 0.0207)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7116 (71.16%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[425  59  53]\n",
            " [ 23 207  55]\n",
            " [ 28  60  54]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          79.14%          88.06%\n",
            "FoG           72.63%          82.47%\n",
            "Transition    38.03%          86.86%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.89      0.79      0.84       537\n",
            "         FoG       0.63      0.73      0.68       285\n",
            "  Transition       0.33      0.38      0.36       142\n",
            "\n",
            "    accuracy                           0.71       964\n",
            "   macro avg       0.62      0.63      0.62       964\n",
            "weighted avg       0.73      0.71      0.72       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training XGBoost\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7314 (+/- 0.0094)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7479 (74.79%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[454  64  19]\n",
            " [ 37 241   7]\n",
            " [ 36  80  26]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.54%          82.90%\n",
            "FoG           84.56%          78.79%\n",
            "Transition    18.31%          96.84%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.86      0.85      0.85       537\n",
            "         FoG       0.63      0.85      0.72       285\n",
            "  Transition       0.50      0.18      0.27       142\n",
            "\n",
            "    accuracy                           0.75       964\n",
            "   macro avg       0.66      0.62      0.61       964\n",
            "weighted avg       0.74      0.75      0.73       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training Gradient Boosting\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7265 (+/- 0.0161)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7438 (74.38%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[458  56  23]\n",
            " [ 42 227  16]\n",
            " [ 39  71  32]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          85.29%          81.03%\n",
            "FoG           79.65%          81.30%\n",
            "Transition    22.54%          95.26%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.85      0.85      0.85       537\n",
            "         FoG       0.64      0.80      0.71       285\n",
            "  Transition       0.45      0.23      0.30       142\n",
            "\n",
            "    accuracy                           0.74       964\n",
            "   macro avg       0.65      0.62      0.62       964\n",
            "weighted avg       0.73      0.74      0.73       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training RBF-SVM\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.6482 (+/- 0.0194)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.6234 (62.34%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[393  43 101]\n",
            " [ 41 143 101]\n",
            " [ 21  56  65]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          73.18%          85.48%\n",
            "FoG           50.18%          85.42%\n",
            "Transition    45.77%          75.43%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.86      0.73      0.79       537\n",
            "         FoG       0.59      0.50      0.54       285\n",
            "  Transition       0.24      0.46      0.32       142\n",
            "\n",
            "    accuracy                           0.62       964\n",
            "   macro avg       0.57      0.56      0.55       964\n",
            "weighted avg       0.69      0.62      0.65       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training MLP\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7026 (+/- 0.0120)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7085 (70.85%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[454  82   1]\n",
            " [ 59 223   3]\n",
            " [ 46  90   6]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.54%          75.41%\n",
            "FoG           78.25%          74.67%\n",
            "Transition     4.23%          99.51%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.81      0.85      0.83       537\n",
            "         FoG       0.56      0.78      0.66       285\n",
            "  Transition       0.60      0.04      0.08       142\n",
            "\n",
            "    accuracy                           0.71       964\n",
            "   macro avg       0.66      0.56      0.52       964\n",
            "weighted avg       0.71      0.71      0.67       964\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: 2s - 5 FEATURES\n",
            "======================================================================\n",
            "\n",
            "Model                Accuracy     Walk Sens    FoG Sens     Trans Sens  \n",
            "--------------------------------------------------------------------\n",
            "Random Forest         71.16%       79.14%       72.63%       38.03%\n",
            "XGBoost               74.79%       84.54%       84.56%       18.31%\n",
            "Gradient Boosting     74.38%       85.29%       79.65%       22.54%\n",
            "RBF-SVM               62.34%       73.18%       50.18%       45.77%\n",
            "MLP                   70.85%       84.54%       78.25%        4.23%\n",
            "\n",
            "######################################################################\n",
            "# EVALUATING 2s - 15 FEATURES\n",
            "######################################################################\n",
            "\n",
            "Dataset info:\n",
            "  Training samples: 3854 (Walk=2148, FoG=1137, Trans=569)\n",
            "  Test samples: 964 (Walk=537, FoG=285, Trans=142)\n",
            "\n",
            "============================================================\n",
            "Training Random Forest\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7818 (+/- 0.0256)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7676 (76.76%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[443  56  38]\n",
            " [ 15 245  25]\n",
            " [ 24  66  52]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          82.50%          90.87%\n",
            "FoG           85.96%          82.03%\n",
            "Transition    36.62%          92.34%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.92      0.82      0.87       537\n",
            "         FoG       0.67      0.86      0.75       285\n",
            "  Transition       0.45      0.37      0.40       142\n",
            "\n",
            "    accuracy                           0.77       964\n",
            "   macro avg       0.68      0.68      0.68       964\n",
            "weighted avg       0.78      0.77      0.77       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training XGBoost\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7911 (+/- 0.0098)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7967 (79.67%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[470  46  21]\n",
            " [ 20 252  13]\n",
            " [ 34  62  46]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          87.52%          87.35%\n",
            "FoG           88.42%          84.09%\n",
            "Transition    32.39%          95.86%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.90      0.88      0.89       537\n",
            "         FoG       0.70      0.88      0.78       285\n",
            "  Transition       0.57      0.32      0.41       142\n",
            "\n",
            "    accuracy                           0.80       964\n",
            "   macro avg       0.72      0.69      0.69       964\n",
            "weighted avg       0.79      0.80      0.79       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training Gradient Boosting\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7989 (+/- 0.0108)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7946 (79.46%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[476  42  19]\n",
            " [ 28 241  16]\n",
            " [ 33  60  49]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          88.64%          85.71%\n",
            "FoG           84.56%          84.98%\n",
            "Transition    34.51%          95.74%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.89      0.89      0.89       537\n",
            "         FoG       0.70      0.85      0.77       285\n",
            "  Transition       0.58      0.35      0.43       142\n",
            "\n",
            "    accuracy                           0.79       964\n",
            "   macro avg       0.72      0.69      0.70       964\n",
            "weighted avg       0.79      0.79      0.78       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training RBF-SVM\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7045 (+/- 0.0217)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7044 (70.44%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[393  57  87]\n",
            " [ 21 222  42]\n",
            " [ 12  66  64]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          73.18%          92.27%\n",
            "FoG           77.89%          81.89%\n",
            "Transition    45.07%          84.31%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.92      0.73      0.82       537\n",
            "         FoG       0.64      0.78      0.70       285\n",
            "  Transition       0.33      0.45      0.38       142\n",
            "\n",
            "    accuracy                           0.70       964\n",
            "   macro avg       0.63      0.65      0.63       964\n",
            "weighted avg       0.75      0.70      0.72       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training MLP\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7543 (+/- 0.0219)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7583 (75.83%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[463  50  24]\n",
            " [ 34 233  18]\n",
            " [ 37  70  35]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          86.22%          83.37%\n",
            "FoG           81.75%          82.33%\n",
            "Transition    24.65%          94.89%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.87      0.86      0.86       537\n",
            "         FoG       0.66      0.82      0.73       285\n",
            "  Transition       0.45      0.25      0.32       142\n",
            "\n",
            "    accuracy                           0.76       964\n",
            "   macro avg       0.66      0.64      0.64       964\n",
            "weighted avg       0.75      0.76      0.74       964\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: 2s - 15 FEATURES\n",
            "======================================================================\n",
            "\n",
            "Model                Accuracy     Walk Sens    FoG Sens     Trans Sens  \n",
            "--------------------------------------------------------------------\n",
            "Random Forest         76.76%       82.50%       85.96%       36.62%\n",
            "XGBoost               79.67%       87.52%       88.42%       32.39%\n",
            "Gradient Boosting     79.46%       88.64%       84.56%       34.51%\n",
            "RBF-SVM               70.44%       73.18%       77.89%       45.07%\n",
            "MLP                   75.83%       86.22%       81.75%       24.65%\n",
            "\n",
            "######################################################################\n",
            "# EVALUATING 2s - 30 FEATURES\n",
            "######################################################################\n",
            "\n",
            "Dataset info:\n",
            "  Training samples: 3854 (Walk=2148, FoG=1137, Trans=569)\n",
            "  Test samples: 964 (Walk=537, FoG=285, Trans=142)\n",
            "\n",
            "============================================================\n",
            "Training Random Forest\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7919 (+/- 0.0264)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7697 (76.97%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[445  50  42]\n",
            " [ 20 242  23]\n",
            " [ 26  61  55]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          82.87%          89.23%\n",
            "FoG           84.91%          83.65%\n",
            "Transition    38.73%          92.09%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.91      0.83      0.87       537\n",
            "         FoG       0.69      0.85      0.76       285\n",
            "  Transition       0.46      0.39      0.42       142\n",
            "\n",
            "    accuracy                           0.77       964\n",
            "   macro avg       0.68      0.69      0.68       964\n",
            "weighted avg       0.78      0.77      0.77       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training XGBoost\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.8069 (+/- 0.0136)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.8008 (80.08%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[482  36  19]\n",
            " [ 25 247  13]\n",
            " [ 34  65  43]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          89.76%          86.18%\n",
            "FoG           86.67%          85.13%\n",
            "Transition    30.28%          96.11%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.89      0.90      0.89       537\n",
            "         FoG       0.71      0.87      0.78       285\n",
            "  Transition       0.57      0.30      0.40       142\n",
            "\n",
            "    accuracy                           0.80       964\n",
            "   macro avg       0.72      0.69      0.69       964\n",
            "weighted avg       0.79      0.80      0.79       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training Gradient Boosting\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.8054 (+/- 0.0176)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.8112 (81.12%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[482  36  19]\n",
            " [ 25 247  13]\n",
            " [ 33  56  53]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          89.76%          86.42%\n",
            "FoG           86.67%          86.45%\n",
            "Transition    37.32%          96.11%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.89      0.90      0.90       537\n",
            "         FoG       0.73      0.87      0.79       285\n",
            "  Transition       0.62      0.37      0.47       142\n",
            "\n",
            "    accuracy                           0.81       964\n",
            "   macro avg       0.75      0.71      0.72       964\n",
            "weighted avg       0.80      0.81      0.80       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training RBF-SVM\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7397 (+/- 0.0167)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7210 (72.10%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[405  37  95]\n",
            " [ 19 207  59]\n",
            " [  9  50  83]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          75.42%          93.44%\n",
            "FoG           72.63%          87.19%\n",
            "Transition    58.45%          81.27%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.94      0.75      0.84       537\n",
            "         FoG       0.70      0.73      0.72       285\n",
            "  Transition       0.35      0.58      0.44       142\n",
            "\n",
            "    accuracy                           0.72       964\n",
            "   macro avg       0.66      0.69      0.66       964\n",
            "weighted avg       0.78      0.72      0.74       964\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training MLP\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7774 (+/- 0.0188)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7863 (78.63%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[456  38  43]\n",
            " [ 26 242  17]\n",
            " [ 26  56  60]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.92%          87.82%\n",
            "FoG           84.91%          86.16%\n",
            "Transition    42.25%          92.70%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.90      0.85      0.87       537\n",
            "         FoG       0.72      0.85      0.78       285\n",
            "  Transition       0.50      0.42      0.46       142\n",
            "\n",
            "    accuracy                           0.79       964\n",
            "   macro avg       0.71      0.71      0.70       964\n",
            "weighted avg       0.79      0.79      0.78       964\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: 2s - 30 FEATURES\n",
            "======================================================================\n",
            "\n",
            "Model                Accuracy     Walk Sens    FoG Sens     Trans Sens  \n",
            "--------------------------------------------------------------------\n",
            "Random Forest         76.97%       82.87%       84.91%       38.73%\n",
            "XGBoost               80.08%       89.76%       86.67%       30.28%\n",
            "Gradient Boosting     81.12%       89.76%       86.67%       37.32%\n",
            "RBF-SVM               72.10%       75.42%       72.63%       58.45%\n",
            "MLP                   78.63%       84.92%       84.91%       42.25%\n",
            "\n",
            "######################################################################\n",
            "# EVALUATING 3s - 5 FEATURES\n",
            "######################################################################\n",
            "\n",
            "Dataset info:\n",
            "  Training samples: 2968 (Walk=1261, FoG=1138, Trans=569)\n",
            "  Test samples: 742 (Walk=316, FoG=284, Trans=142)\n",
            "\n",
            "============================================================\n",
            "Training Random Forest\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7359 (+/- 0.0352)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7129 (71.29%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[247  37  32]\n",
            " [ 14 219  51]\n",
            " [ 30  49  63]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          78.16%          89.67%\n",
            "FoG           77.11%          81.22%\n",
            "Transition    44.37%          86.17%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.85      0.78      0.81       316\n",
            "         FoG       0.72      0.77      0.74       284\n",
            "  Transition       0.43      0.44      0.44       142\n",
            "\n",
            "    accuracy                           0.71       742\n",
            "   macro avg       0.67      0.67      0.66       742\n",
            "weighted avg       0.72      0.71      0.71       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training XGBoost\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7436 (+/- 0.0216)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7251 (72.51%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[254  47  15]\n",
            " [ 17 246  21]\n",
            " [ 40  64  38]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          80.38%          86.62%\n",
            "FoG           86.62%          75.76%\n",
            "Transition    26.76%          94.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.82      0.80      0.81       316\n",
            "         FoG       0.69      0.87      0.77       284\n",
            "  Transition       0.51      0.27      0.35       142\n",
            "\n",
            "    accuracy                           0.73       742\n",
            "   macro avg       0.67      0.65      0.64       742\n",
            "weighted avg       0.71      0.73      0.71       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training Gradient Boosting\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7402 (+/- 0.0187)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7264 (72.64%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[253  42  21]\n",
            " [ 16 238  30]\n",
            " [ 36  58  48]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          80.06%          87.79%\n",
            "FoG           83.80%          78.17%\n",
            "Transition    33.80%          91.50%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.83      0.80      0.81       316\n",
            "         FoG       0.70      0.84      0.77       284\n",
            "  Transition       0.48      0.34      0.40       142\n",
            "\n",
            "    accuracy                           0.73       742\n",
            "   macro avg       0.67      0.66      0.66       742\n",
            "weighted avg       0.72      0.73      0.72       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training RBF-SVM\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.6469 (+/- 0.0298)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.6361 (63.61%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[206  46  64]\n",
            " [ 24 190  70]\n",
            " [ 19  47  76]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          65.19%          89.91%\n",
            "FoG           66.90%          79.69%\n",
            "Transition    53.52%          77.67%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.83      0.65      0.73       316\n",
            "         FoG       0.67      0.67      0.67       284\n",
            "  Transition       0.36      0.54      0.43       142\n",
            "\n",
            "    accuracy                           0.64       742\n",
            "   macro avg       0.62      0.62      0.61       742\n",
            "weighted avg       0.68      0.64      0.65       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training MLP\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.6809 (+/- 0.0232)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.6900 (69.00%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[244  52  20]\n",
            " [ 30 234  20]\n",
            " [ 34  74  34]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          77.22%          84.98%\n",
            "FoG           82.39%          72.49%\n",
            "Transition    23.94%          93.33%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.79      0.77      0.78       316\n",
            "         FoG       0.65      0.82      0.73       284\n",
            "  Transition       0.46      0.24      0.31       142\n",
            "\n",
            "    accuracy                           0.69       742\n",
            "   macro avg       0.63      0.61      0.61       742\n",
            "weighted avg       0.67      0.69      0.67       742\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: 3s - 5 FEATURES\n",
            "======================================================================\n",
            "\n",
            "Model                Accuracy     Walk Sens    FoG Sens     Trans Sens  \n",
            "--------------------------------------------------------------------\n",
            "Random Forest         71.29%       78.16%       77.11%       44.37%\n",
            "XGBoost               72.51%       80.38%       86.62%       26.76%\n",
            "Gradient Boosting     72.64%       80.06%       83.80%       33.80%\n",
            "RBF-SVM               63.61%       65.19%       66.90%       53.52%\n",
            "MLP                   69.00%       77.22%       82.39%       23.94%\n",
            "\n",
            "######################################################################\n",
            "# EVALUATING 3s - 15 FEATURES\n",
            "######################################################################\n",
            "\n",
            "Dataset info:\n",
            "  Training samples: 2968 (Walk=1261, FoG=1138, Trans=569)\n",
            "  Test samples: 742 (Walk=316, FoG=284, Trans=142)\n",
            "\n",
            "============================================================\n",
            "Training Random Forest\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7736 (+/- 0.0324)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7547 (75.47%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[255  26  35]\n",
            " [ 13 231  40]\n",
            " [ 23  45  74]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          80.70%          91.55%\n",
            "FoG           81.34%          84.50%\n",
            "Transition    52.11%          87.50%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.88      0.81      0.84       316\n",
            "         FoG       0.76      0.81      0.79       284\n",
            "  Transition       0.50      0.52      0.51       142\n",
            "\n",
            "    accuracy                           0.75       742\n",
            "   macro avg       0.71      0.71      0.71       742\n",
            "weighted avg       0.76      0.75      0.76       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training XGBoost\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7847 (+/- 0.0305)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7776 (77.76%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[264  26  26]\n",
            " [ 12 246  26]\n",
            " [ 26  49  67]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          83.54%          91.08%\n",
            "FoG           86.62%          83.62%\n",
            "Transition    47.18%          91.33%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.87      0.84      0.85       316\n",
            "         FoG       0.77      0.87      0.81       284\n",
            "  Transition       0.56      0.47      0.51       142\n",
            "\n",
            "    accuracy                           0.78       742\n",
            "   macro avg       0.73      0.72      0.73       742\n",
            "weighted avg       0.77      0.78      0.77       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training Gradient Boosting\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7810 (+/- 0.0289)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7817 (78.17%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[266  25  25]\n",
            " [ 13 248  23]\n",
            " [ 28  48  66]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.18%          90.38%\n",
            "FoG           87.32%          84.06%\n",
            "Transition    46.48%          92.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.87      0.84      0.85       316\n",
            "         FoG       0.77      0.87      0.82       284\n",
            "  Transition       0.58      0.46      0.52       142\n",
            "\n",
            "    accuracy                           0.78       742\n",
            "   macro avg       0.74      0.73      0.73       742\n",
            "weighted avg       0.78      0.78      0.78       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training RBF-SVM\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7156 (+/- 0.0363)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.6873 (68.73%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[221  32  63]\n",
            " [ 27 203  54]\n",
            " [ 15  41  86]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          69.94%          90.14%\n",
            "FoG           71.48%          84.06%\n",
            "Transition    60.56%          80.50%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.84      0.70      0.76       316\n",
            "         FoG       0.74      0.71      0.72       284\n",
            "  Transition       0.42      0.61      0.50       142\n",
            "\n",
            "    accuracy                           0.69       742\n",
            "   macro avg       0.67      0.67      0.66       742\n",
            "weighted avg       0.72      0.69      0.70       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training MLP\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7140 (+/- 0.0277)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7197 (71.97%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[238  47  31]\n",
            " [ 20 236  28]\n",
            " [ 27  55  60]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          75.32%          88.97%\n",
            "FoG           83.10%          77.73%\n",
            "Transition    42.25%          90.17%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.84      0.75      0.79       316\n",
            "         FoG       0.70      0.83      0.76       284\n",
            "  Transition       0.50      0.42      0.46       142\n",
            "\n",
            "    accuracy                           0.72       742\n",
            "   macro avg       0.68      0.67      0.67       742\n",
            "weighted avg       0.72      0.72      0.72       742\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: 3s - 15 FEATURES\n",
            "======================================================================\n",
            "\n",
            "Model                Accuracy     Walk Sens    FoG Sens     Trans Sens  \n",
            "--------------------------------------------------------------------\n",
            "Random Forest         75.47%       80.70%       81.34%       52.11%\n",
            "XGBoost               77.76%       83.54%       86.62%       47.18%\n",
            "Gradient Boosting     78.17%       84.18%       87.32%       46.48%\n",
            "RBF-SVM               68.73%       69.94%       71.48%       60.56%\n",
            "MLP                   71.97%       75.32%       83.10%       42.25%\n",
            "\n",
            "######################################################################\n",
            "# EVALUATING 3s - 30 FEATURES\n",
            "######################################################################\n",
            "\n",
            "Dataset info:\n",
            "  Training samples: 2968 (Walk=1261, FoG=1138, Trans=569)\n",
            "  Test samples: 742 (Walk=316, FoG=284, Trans=142)\n",
            "\n",
            "============================================================\n",
            "Training Random Forest\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7908 (+/- 0.0227)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7951 (79.51%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[258  28  30]\n",
            " [  9 251  24]\n",
            " [ 20  41  81]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          81.65%          93.19%\n",
            "FoG           88.38%          84.93%\n",
            "Transition    57.04%          91.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.90      0.82      0.86       316\n",
            "         FoG       0.78      0.88      0.83       284\n",
            "  Transition       0.60      0.57      0.58       142\n",
            "\n",
            "    accuracy                           0.80       742\n",
            "   macro avg       0.76      0.76      0.76       742\n",
            "weighted avg       0.80      0.80      0.79       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training XGBoost\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.8002 (+/- 0.0211)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.8005 (80.05%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[267  23  26]\n",
            " [ 14 250  20]\n",
            " [ 25  40  77]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.49%          90.85%\n",
            "FoG           88.03%          86.24%\n",
            "Transition    54.23%          92.33%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.87      0.84      0.86       316\n",
            "         FoG       0.80      0.88      0.84       284\n",
            "  Transition       0.63      0.54      0.58       142\n",
            "\n",
            "    accuracy                           0.80       742\n",
            "   macro avg       0.77      0.76      0.76       742\n",
            "weighted avg       0.80      0.80      0.80       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training Gradient Boosting\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.8117 (+/- 0.0288)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.8005 (80.05%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[266  22  28]\n",
            " [ 15 247  22]\n",
            " [ 22  39  81]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.18%          91.31%\n",
            "FoG           86.97%          86.68%\n",
            "Transition    57.04%          91.67%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.88      0.84      0.86       316\n",
            "         FoG       0.80      0.87      0.83       284\n",
            "  Transition       0.62      0.57      0.59       142\n",
            "\n",
            "    accuracy                           0.80       742\n",
            "   macro avg       0.77      0.76      0.76       742\n",
            "weighted avg       0.80      0.80      0.80       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training RBF-SVM\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7503 (+/- 0.0406)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7561 (75.61%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[244  20  52]\n",
            " [ 20 216  48]\n",
            " [ 13  28 101]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          77.22%          92.25%\n",
            "FoG           76.06%          89.52%\n",
            "Transition    71.13%          83.33%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.88      0.77      0.82       316\n",
            "         FoG       0.82      0.76      0.79       284\n",
            "  Transition       0.50      0.71      0.59       142\n",
            "\n",
            "    accuracy                           0.76       742\n",
            "   macro avg       0.73      0.75      0.73       742\n",
            "weighted avg       0.78      0.76      0.76       742\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training MLP\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7638 (+/- 0.0314)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7480 (74.80%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[257  27  32]\n",
            " [ 25 231  28]\n",
            " [ 28  47  67]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          81.33%          87.56%\n",
            "FoG           81.34%          83.84%\n",
            "Transition    47.18%          90.00%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.83      0.81      0.82       316\n",
            "         FoG       0.76      0.81      0.78       284\n",
            "  Transition       0.53      0.47      0.50       142\n",
            "\n",
            "    accuracy                           0.75       742\n",
            "   macro avg       0.70      0.70      0.70       742\n",
            "weighted avg       0.74      0.75      0.75       742\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: 3s - 30 FEATURES\n",
            "======================================================================\n",
            "\n",
            "Model                Accuracy     Walk Sens    FoG Sens     Trans Sens  \n",
            "--------------------------------------------------------------------\n",
            "Random Forest         79.51%       81.65%       88.38%       57.04%\n",
            "XGBoost               80.05%       84.49%       88.03%       54.23%\n",
            "Gradient Boosting     80.05%       84.18%       86.97%       57.04%\n",
            "RBF-SVM               75.61%       77.22%       76.06%       71.13%\n",
            "MLP                   74.80%       81.33%       81.34%       47.18%\n",
            "\n",
            "######################################################################\n",
            "# EVALUATING 4s - 5 FEATURES\n",
            "######################################################################\n",
            "\n",
            "Dataset info:\n",
            "  Training samples: 2229 (Walk=830, FoG=830, Trans=569)\n",
            "  Test samples: 558 (Walk=208, FoG=208, Trans=142)\n",
            "\n",
            "============================================================\n",
            "Training Random Forest\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7048 (+/- 0.0186)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7061 (70.61%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[151  23  34]\n",
            " [ 12 170  26]\n",
            " [ 36  33  73]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          72.60%          86.29%\n",
            "FoG           81.73%          84.00%\n",
            "Transition    51.41%          85.58%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.76      0.73      0.74       208\n",
            "         FoG       0.75      0.82      0.78       208\n",
            "  Transition       0.55      0.51      0.53       142\n",
            "\n",
            "    accuracy                           0.71       558\n",
            "   macro avg       0.69      0.69      0.69       558\n",
            "weighted avg       0.70      0.71      0.70       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training XGBoost\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7039 (+/- 0.0109)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7133 (71.33%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[158  25  25]\n",
            " [ 11 179  18]\n",
            " [ 38  43  61]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          75.96%          86.00%\n",
            "FoG           86.06%          80.57%\n",
            "Transition    42.96%          89.66%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.76      0.76      0.76       208\n",
            "         FoG       0.72      0.86      0.79       208\n",
            "  Transition       0.59      0.43      0.50       142\n",
            "\n",
            "    accuracy                           0.71       558\n",
            "   macro avg       0.69      0.68      0.68       558\n",
            "weighted avg       0.70      0.71      0.70       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training Gradient Boosting\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7026 (+/- 0.0223)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7097 (70.97%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[155  24  29]\n",
            " [ 12 176  20]\n",
            " [ 40  37  65]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          74.52%          85.14%\n",
            "FoG           84.62%          82.57%\n",
            "Transition    45.77%          88.22%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.75      0.75      0.75       208\n",
            "         FoG       0.74      0.85      0.79       208\n",
            "  Transition       0.57      0.46      0.51       142\n",
            "\n",
            "    accuracy                           0.71       558\n",
            "   macro avg       0.69      0.68      0.68       558\n",
            "weighted avg       0.70      0.71      0.70       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training RBF-SVM\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.5644 (+/- 0.0149)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.5789 (57.89%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 82  96  30]\n",
            " [  5 196   7]\n",
            " [ 25  72  45]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          39.42%          91.43%\n",
            "FoG           94.23%          52.00%\n",
            "Transition    31.69%          91.11%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.73      0.39      0.51       208\n",
            "         FoG       0.54      0.94      0.69       208\n",
            "  Transition       0.55      0.32      0.40       142\n",
            "\n",
            "    accuracy                           0.58       558\n",
            "   macro avg       0.61      0.55      0.53       558\n",
            "weighted avg       0.61      0.58      0.55       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training MLP\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.5841 (+/- 0.0229)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.5986 (59.86%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[148  48  12]\n",
            " [ 47 156   5]\n",
            " [ 62  50  30]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          71.15%          68.86%\n",
            "FoG           75.00%          72.00%\n",
            "Transition    21.13%          95.91%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.58      0.71      0.64       208\n",
            "         FoG       0.61      0.75      0.68       208\n",
            "  Transition       0.64      0.21      0.32       142\n",
            "\n",
            "    accuracy                           0.60       558\n",
            "   macro avg       0.61      0.56      0.54       558\n",
            "weighted avg       0.61      0.60      0.57       558\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: 4s - 5 FEATURES\n",
            "======================================================================\n",
            "\n",
            "Model                Accuracy     Walk Sens    FoG Sens     Trans Sens  \n",
            "--------------------------------------------------------------------\n",
            "Random Forest         70.61%       72.60%       81.73%       51.41%\n",
            "XGBoost               71.33%       75.96%       86.06%       42.96%\n",
            "Gradient Boosting     70.97%       74.52%       84.62%       45.77%\n",
            "RBF-SVM               57.89%       39.42%       94.23%       31.69%\n",
            "MLP                   59.86%       71.15%       75.00%       21.13%\n",
            "\n",
            "######################################################################\n",
            "# EVALUATING 4s - 15 FEATURES\n",
            "######################################################################\n",
            "\n",
            "Dataset info:\n",
            "  Training samples: 2229 (Walk=830, FoG=830, Trans=569)\n",
            "  Test samples: 558 (Walk=208, FoG=208, Trans=142)\n",
            "\n",
            "============================================================\n",
            "Training Random Forest\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7725 (+/- 0.0182)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7849 (78.49%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[166  18  24]\n",
            " [  5 188  15]\n",
            " [ 27  31  84]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          79.81%          90.86%\n",
            "FoG           90.38%          86.00%\n",
            "Transition    59.15%          90.62%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.84      0.80      0.82       208\n",
            "         FoG       0.79      0.90      0.84       208\n",
            "  Transition       0.68      0.59      0.63       142\n",
            "\n",
            "    accuracy                           0.78       558\n",
            "   macro avg       0.77      0.76      0.77       558\n",
            "weighted avg       0.78      0.78      0.78       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training XGBoost\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7819 (+/- 0.0186)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.8029 (80.29%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[169  15  24]\n",
            " [  5 189  14]\n",
            " [ 28  24  90]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          81.25%          90.57%\n",
            "FoG           90.87%          88.86%\n",
            "Transition    63.38%          90.87%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.84      0.81      0.82       208\n",
            "         FoG       0.83      0.91      0.87       208\n",
            "  Transition       0.70      0.63      0.67       142\n",
            "\n",
            "    accuracy                           0.80       558\n",
            "   macro avg       0.79      0.78      0.79       558\n",
            "weighted avg       0.80      0.80      0.80       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training Gradient Boosting\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7707 (+/- 0.0164)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.8172 (81.72%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[175  14  19]\n",
            " [  6 189  13]\n",
            " [ 24  26  92]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.13%          91.43%\n",
            "FoG           90.87%          88.57%\n",
            "Transition    64.79%          92.31%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.85      0.84      0.85       208\n",
            "         FoG       0.83      0.91      0.86       208\n",
            "  Transition       0.74      0.65      0.69       142\n",
            "\n",
            "    accuracy                           0.82       558\n",
            "   macro avg       0.81      0.80      0.80       558\n",
            "weighted avg       0.81      0.82      0.81       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training RBF-SVM\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7259 (+/- 0.0178)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7473 (74.73%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[147  25  36]\n",
            " [  6 175  27]\n",
            " [ 22  25  95]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          70.67%          92.00%\n",
            "FoG           84.13%          85.71%\n",
            "Transition    66.90%          84.86%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.84      0.71      0.77       208\n",
            "         FoG       0.78      0.84      0.81       208\n",
            "  Transition       0.60      0.67      0.63       142\n",
            "\n",
            "    accuracy                           0.75       558\n",
            "   macro avg       0.74      0.74      0.74       558\n",
            "weighted avg       0.76      0.75      0.75       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training MLP\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7250 (+/- 0.0259)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7151 (71.51%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[161  31  16]\n",
            " [ 17 173  18]\n",
            " [ 46  31  65]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          77.40%          82.00%\n",
            "FoG           83.17%          82.29%\n",
            "Transition    45.77%          91.83%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.72      0.77      0.75       208\n",
            "         FoG       0.74      0.83      0.78       208\n",
            "  Transition       0.66      0.46      0.54       142\n",
            "\n",
            "    accuracy                           0.72       558\n",
            "   macro avg       0.70      0.69      0.69       558\n",
            "weighted avg       0.71      0.72      0.71       558\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: 4s - 15 FEATURES\n",
            "======================================================================\n",
            "\n",
            "Model                Accuracy     Walk Sens    FoG Sens     Trans Sens  \n",
            "--------------------------------------------------------------------\n",
            "Random Forest         78.49%       79.81%       90.38%       59.15%\n",
            "XGBoost               80.29%       81.25%       90.87%       63.38%\n",
            "Gradient Boosting     81.72%       84.13%       90.87%       64.79%\n",
            "RBF-SVM               74.73%       70.67%       84.13%       66.90%\n",
            "MLP                   71.51%       77.40%       83.17%       45.77%\n",
            "\n",
            "######################################################################\n",
            "# EVALUATING 4s - 30 FEATURES\n",
            "######################################################################\n",
            "\n",
            "Dataset info:\n",
            "  Training samples: 2229 (Walk=830, FoG=830, Trans=569)\n",
            "  Test samples: 558 (Walk=208, FoG=208, Trans=142)\n",
            "\n",
            "============================================================\n",
            "Training Random Forest\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7860 (+/- 0.0220)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.8082 (80.82%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[173  14  21]\n",
            " [  4 185  19]\n",
            " [ 24  25  93]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          83.17%          92.00%\n",
            "FoG           88.94%          88.86%\n",
            "Transition    65.49%          90.38%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.86      0.83      0.85       208\n",
            "         FoG       0.83      0.89      0.86       208\n",
            "  Transition       0.70      0.65      0.68       142\n",
            "\n",
            "    accuracy                           0.81       558\n",
            "   macro avg       0.80      0.79      0.79       558\n",
            "weighted avg       0.81      0.81      0.81       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training XGBoost\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.8030 (+/- 0.0209)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.8118 (81.18%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[174  14  20]\n",
            " [  3 185  20]\n",
            " [ 25  23  94]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          83.65%          92.00%\n",
            "FoG           88.94%          89.43%\n",
            "Transition    66.20%          90.38%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.86      0.84      0.85       208\n",
            "         FoG       0.83      0.89      0.86       208\n",
            "  Transition       0.70      0.66      0.68       142\n",
            "\n",
            "    accuracy                           0.81       558\n",
            "   macro avg       0.80      0.80      0.80       558\n",
            "weighted avg       0.81      0.81      0.81       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training Gradient Boosting\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7999 (+/- 0.0215)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.8190 (81.90%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[179  11  18]\n",
            " [  4 184  20]\n",
            " [ 24  24  94]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          86.06%          92.00%\n",
            "FoG           88.46%          90.00%\n",
            "Transition    66.20%          90.87%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.86      0.86      0.86       208\n",
            "         FoG       0.84      0.88      0.86       208\n",
            "  Transition       0.71      0.66      0.69       142\n",
            "\n",
            "    accuracy                           0.82       558\n",
            "   macro avg       0.81      0.80      0.80       558\n",
            "weighted avg       0.82      0.82      0.82       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training RBF-SVM\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7487 (+/- 0.0321)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7885 (78.85%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[162  17  29]\n",
            " [  9 177  22]\n",
            " [ 21  20 101]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          77.88%          91.43%\n",
            "FoG           85.10%          89.43%\n",
            "Transition    71.13%          87.74%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.84      0.78      0.81       208\n",
            "         FoG       0.83      0.85      0.84       208\n",
            "  Transition       0.66      0.71      0.69       142\n",
            "\n",
            "    accuracy                           0.79       558\n",
            "   macro avg       0.78      0.78      0.78       558\n",
            "weighted avg       0.79      0.79      0.79       558\n",
            "\n",
            "\n",
            "============================================================\n",
            "Training MLP\n",
            "============================================================\n",
            "Performing 10-fold cross-validation on training set...\n",
            "CV Accuracy: 0.7470 (+/- 0.0202)\n",
            "Training on full training set...\n",
            "\n",
            "Evaluating on test set...\n",
            "Test Accuracy: 0.7760 (77.60%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[177  20  11]\n",
            " [  7 179  22]\n",
            " [ 37  28  77]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          85.10%          87.43%\n",
            "FoG           86.06%          86.29%\n",
            "Transition    54.23%          92.07%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Walk       0.80      0.85      0.83       208\n",
            "         FoG       0.79      0.86      0.82       208\n",
            "  Transition       0.70      0.54      0.61       142\n",
            "\n",
            "    accuracy                           0.78       558\n",
            "   macro avg       0.76      0.75      0.75       558\n",
            "weighted avg       0.77      0.78      0.77       558\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: 4s - 30 FEATURES\n",
            "======================================================================\n",
            "\n",
            "Model                Accuracy     Walk Sens    FoG Sens     Trans Sens  \n",
            "--------------------------------------------------------------------\n",
            "Random Forest         80.82%       83.17%       88.94%       65.49%\n",
            "XGBoost               81.18%       83.65%       88.94%       66.20%\n",
            "Gradient Boosting     81.90%       86.06%       88.46%       66.20%\n",
            "RBF-SVM               78.85%       77.88%       85.10%       71.13%\n",
            "MLP                   77.60%       85.10%       86.06%       54.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import copy\n",
        "\n",
        "class Hellsemble(BaseEstimator, ClassifierMixin):\n",
        "    \"\"\"\n",
        "    Hellsemble: A novel ensemble learning framework that partitions data\n",
        "    by difficulty and uses a router to direct instances to specialized models.\n",
        "\n",
        "    Based on: \"Divide, Specialize, and Route: A New Approach to Efficient\n",
        "    Ensemble Learning\" (arXiv:2506.20814v1)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_models, router_model, mode='sequential',\n",
        "                 alpha=0.3, val_size=0.2, metric='accuracy',\n",
        "                 max_iterations=None, verbose=True, random_state=42):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -----------\n",
        "        base_models : list\n",
        "            List of sklearn-compatible classifier objects to use as base models\n",
        "        router_model : classifier\n",
        "            sklearn-compatible classifier to use as router\n",
        "        mode : str, default='sequential'\n",
        "            'sequential' or 'greedy' - training strategy\n",
        "        alpha : float, default=0.3\n",
        "            Fraction of correctly classified instances to include in next iteration\n",
        "            (for regularization)\n",
        "        val_size : float, default=0.2\n",
        "            Fraction of data to use for validation during training\n",
        "        metric : str, default='accuracy'\n",
        "            Metric to optimize ('accuracy', 'balanced_accuracy', etc.)\n",
        "        max_iterations : int, optional\n",
        "            Maximum number of iterations (circles of difficulty)\n",
        "        verbose : bool, default=True\n",
        "            Whether to print progress\n",
        "        random_state : int, default=42\n",
        "            Random seed for reproducibility\n",
        "        \"\"\"\n",
        "        self.base_models = base_models\n",
        "        self.router_model = router_model\n",
        "        self.mode = mode\n",
        "        self.alpha = alpha\n",
        "        self.val_size = val_size\n",
        "        self.metric = metric\n",
        "        self.max_iterations = max_iterations if max_iterations else len(base_models)\n",
        "        self.verbose = verbose\n",
        "        self.random_state = random_state\n",
        "\n",
        "        # Will be populated during fit\n",
        "        self.ensemble_ = []  # List of (model, circle_id) tuples\n",
        "        self.router_ = None\n",
        "        self.n_circles_ = 0\n",
        "\n",
        "    def _compute_metric(self, y_true, y_pred):\n",
        "        \"\"\"Compute the specified metric\"\"\"\n",
        "        if self.metric == 'accuracy':\n",
        "            return accuracy_score(y_true, y_pred)\n",
        "        elif self.metric == 'balanced_accuracy':\n",
        "            from sklearn.metrics import balanced_accuracy_score\n",
        "            return balanced_accuracy_score(y_true, y_pred)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported metric: {self.metric}\")\n",
        "\n",
        "    def _evaluate_ensemble(self, X_val, y_val):\n",
        "        \"\"\"Evaluate current ensemble on validation set using router\"\"\"\n",
        "        if not self.ensemble_:\n",
        "            return 0.0\n",
        "\n",
        "        # Train temporary router\n",
        "        temp_router = copy.deepcopy(self.router_model)\n",
        "        temp_router.fit(self.router_X_, self.router_y_)\n",
        "\n",
        "        # Predict using router\n",
        "        circle_predictions = temp_router.predict(X_val)\n",
        "\n",
        "        # Get predictions from appropriate models\n",
        "        y_pred = np.zeros(len(X_val))\n",
        "        for i, circle_id in enumerate(circle_predictions):\n",
        "            # Find model for this circle\n",
        "            if circle_id < len(self.ensemble_):\n",
        "                model, _ = self.ensemble_[circle_id]\n",
        "                y_pred[i] = model.predict(X_val[i:i+1])[0]\n",
        "            else:\n",
        "                # Fallback to last model if router predicts non-existent circle\n",
        "                model, _ = self.ensemble_[-1]\n",
        "                y_pred[i] = model.predict(X_val[i:i+1])[0]\n",
        "\n",
        "        return self._compute_metric(y_val, y_pred)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit Hellsemble on training data\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training data\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target values\n",
        "        \"\"\"\n",
        "        # Split into train and validation\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y, test_size=self.val_size, stratify=y, random_state=self.random_state\n",
        "        )\n",
        "\n",
        "        # Initialize\n",
        "        self.ensemble_ = []\n",
        "        self.router_X_ = np.empty((0, X_train.shape[1]))\n",
        "        self.router_y_ = np.array([], dtype=int)\n",
        "\n",
        "        prev_score = 0.0\n",
        "        current_X_train = X_train.copy()\n",
        "        current_y_train = y_train.copy()\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Training Hellsemble ({self.mode} mode)\")\n",
        "            print(f\"{'='*60}\")\n",
        "            print(f\"Initial training samples: {len(X_train)}\")\n",
        "            print(f\"Validation samples: {len(X_val)}\")\n",
        "\n",
        "        # Main iteration loop\n",
        "        for iteration in range(self.max_iterations):\n",
        "            if len(current_X_train) == 0:\n",
        "                if self.verbose:\n",
        "                    print(f\"\\nStopping: No more training samples\")\n",
        "                break\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f\"\\n--- Circle {iteration} ---\")\n",
        "                print(f\"Training samples: {len(current_X_train)}\")\n",
        "\n",
        "            # Select best model for this iteration\n",
        "            if self.mode == 'sequential':\n",
        "                # Use next model in sequence\n",
        "                if iteration >= len(self.base_models):\n",
        "                    if self.verbose:\n",
        "                        print(f\"Stopping: No more base models\")\n",
        "                    break\n",
        "                best_model = copy.deepcopy(self.base_models[iteration])\n",
        "                best_model.fit(current_X_train, current_y_train)\n",
        "\n",
        "            elif self.mode == 'greedy':\n",
        "                # Try all models and pick best\n",
        "                best_score = -np.inf\n",
        "                best_model = None\n",
        "\n",
        "                for model_idx, base_model in enumerate(self.base_models):\n",
        "                    # Train candidate model\n",
        "                    candidate = copy.deepcopy(base_model)\n",
        "                    candidate.fit(current_X_train, current_y_train)\n",
        "\n",
        "                    # Temporarily add to ensemble and evaluate\n",
        "                    temp_ensemble = self.ensemble_ + [(candidate, iteration)]\n",
        "                    temp_router_X = np.vstack([self.router_X_, current_X_train])\n",
        "                    temp_router_y = np.concatenate([\n",
        "                        self.router_y_,\n",
        "                        np.full(len(current_X_train), iteration)\n",
        "                    ])\n",
        "\n",
        "                    # Store temporarily for evaluation\n",
        "                    old_ensemble = self.ensemble_\n",
        "                    old_router_X = self.router_X_\n",
        "                    old_router_y = self.router_y_\n",
        "\n",
        "                    self.ensemble_ = temp_ensemble\n",
        "                    self.router_X_ = temp_router_X\n",
        "                    self.router_y_ = temp_router_y\n",
        "\n",
        "                    score = self._evaluate_ensemble(X_val, y_val)\n",
        "\n",
        "                    # Restore\n",
        "                    self.ensemble_ = old_ensemble\n",
        "                    self.router_X_ = old_router_X\n",
        "                    self.router_y_ = old_router_y\n",
        "\n",
        "                    if score > best_score:\n",
        "                        best_score = score\n",
        "                        best_model = candidate\n",
        "\n",
        "                if best_model is None:\n",
        "                    if self.verbose:\n",
        "                        print(f\"Stopping: No model improved performance\")\n",
        "                    break\n",
        "\n",
        "            # Add best model to ensemble\n",
        "            self.ensemble_.append((best_model, iteration))\n",
        "\n",
        "            # Update router training data\n",
        "            self.router_X_ = np.vstack([self.router_X_, current_X_train])\n",
        "            self.router_y_ = np.concatenate([\n",
        "                self.router_y_,\n",
        "                np.full(len(current_X_train), iteration)\n",
        "            ])\n",
        "\n",
        "            # Evaluate current ensemble\n",
        "            current_score = self._evaluate_ensemble(X_val, y_val)\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f\"Validation {self.metric}: {current_score:.4f}\")\n",
        "                print(f\"Model type: {type(best_model).__name__}\")\n",
        "\n",
        "            # Check if performance improved\n",
        "            if current_score <= prev_score and iteration > 0:\n",
        "                # Remove last model and stop\n",
        "                self.ensemble_.pop()\n",
        "                # Remove last batch from router data\n",
        "                n_remove = len(current_X_train)\n",
        "                self.router_X_ = self.router_X_[:-n_remove]\n",
        "                self.router_y_ = self.router_y_[:-n_remove]\n",
        "\n",
        "                if self.verbose:\n",
        "                    print(f\"Stopping: No improvement ({current_score:.4f} <= {prev_score:.4f})\")\n",
        "                break\n",
        "\n",
        "            prev_score = current_score\n",
        "\n",
        "            # Identify misclassified instances\n",
        "            train_predictions = best_model.predict(current_X_train)\n",
        "            misclassified_mask = train_predictions != current_y_train\n",
        "            correctly_classified_mask = ~misclassified_mask\n",
        "\n",
        "            n_misclassified = np.sum(misclassified_mask)\n",
        "            n_correct = np.sum(correctly_classified_mask)\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f\"Misclassified: {n_misclassified}, Correct: {n_correct}\")\n",
        "\n",
        "            if n_misclassified == 0:\n",
        "                if self.verbose:\n",
        "                    print(f\"Stopping: All instances classified correctly\")\n",
        "                break\n",
        "\n",
        "            # Prepare next iteration's training set\n",
        "            # Include all misclassified + fraction of correctly classified\n",
        "            hard_indices = np.where(misclassified_mask)[0]\n",
        "            easy_indices = np.where(correctly_classified_mask)[0]\n",
        "\n",
        "            # Sample alpha fraction of correctly classified\n",
        "            n_easy_to_include = int(self.alpha * n_correct)\n",
        "            if n_easy_to_include > 0 and len(easy_indices) > 0:\n",
        "                rng = np.random.RandomState(self.random_state + iteration)\n",
        "                selected_easy = rng.choice(easy_indices, size=n_easy_to_include, replace=False)\n",
        "                next_indices = np.concatenate([hard_indices, selected_easy])\n",
        "            else:\n",
        "                next_indices = hard_indices\n",
        "\n",
        "            current_X_train = current_X_train[next_indices]\n",
        "            current_y_train = current_y_train[next_indices]\n",
        "\n",
        "        # Train final router\n",
        "        self.n_circles_ = len(self.ensemble_)\n",
        "        if self.n_circles_ > 0:\n",
        "            self.router_ = copy.deepcopy(self.router_model)\n",
        "            self.router_.fit(self.router_X_, self.router_y_)\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f\"\\n{'='*60}\")\n",
        "                print(f\" Training complete!\")\n",
        "                print(f\"   Total circles: {self.n_circles_}\")\n",
        "                print(f\"   Final validation {self.metric}: {prev_score:.4f}\")\n",
        "                print(f\"{'='*60}\\n\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict class labels for samples in X\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Samples to predict\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        y_pred : array of shape (n_samples,)\n",
        "            Predicted class labels\n",
        "        \"\"\"\n",
        "        if not self.ensemble_:\n",
        "            raise ValueError(\"Ensemble is empty. Call fit() first.\")\n",
        "\n",
        "        # Use router to determine which model to use for each instance\n",
        "        circle_predictions = self.router_.predict(X)\n",
        "\n",
        "        # Get predictions from appropriate models\n",
        "        y_pred = np.zeros(len(X), dtype=int)\n",
        "        for i, circle_id in enumerate(circle_predictions):\n",
        "            # Ensure circle_id is valid\n",
        "            circle_id = min(circle_id, len(self.ensemble_) - 1)\n",
        "            model, _ = self.ensemble_[circle_id]\n",
        "            y_pred[i] = model.predict(X[i:i+1])[0]\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Predict class probabilities for samples in X\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Samples to predict\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        proba : array of shape (n_samples, n_classes)\n",
        "            Class probabilities\n",
        "        \"\"\"\n",
        "        if not self.ensemble_:\n",
        "            raise ValueError(\"Ensemble is empty. Call fit() first.\")\n",
        "\n",
        "        # Use router to determine which model to use for each instance\n",
        "        circle_predictions = self.router_.predict(X)\n",
        "\n",
        "        # Determine number of classes from first model\n",
        "        model, _ = self.ensemble_[0]\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            n_classes = len(model.classes_)\n",
        "        else:\n",
        "            raise ValueError(\"Base models must support predict_proba\")\n",
        "\n",
        "        # Get probability predictions from appropriate models\n",
        "        y_proba = np.zeros((len(X), n_classes))\n",
        "        for i, circle_id in enumerate(circle_predictions):\n",
        "            # Ensure circle_id is valid\n",
        "            circle_id = min(circle_id, len(self.ensemble_) - 1)\n",
        "            model, _ = self.ensemble_[circle_id]\n",
        "            y_proba[i] = model.predict_proba(X[i:i+1])[0]\n",
        "\n",
        "        return y_proba\n",
        "\n",
        "# Test the implementation\n",
        "print(\" Hellsemble class implemented successfully!\")\n",
        "print(\"\\nKey features:\")\n",
        "print(\"  - Sequential and Greedy modes\")\n",
        "print(\"  - Difficulty-based instance routing\")\n",
        "print(\"  - Automatic stopping when no improvement\")\n",
        "print(\"  - Compatible with scikit-learn API\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHvfQE_puFMC",
        "outputId": "d861c996-c5c4-4171-9598-eef90d38d1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Hellsemble class implemented successfully!\n",
            "\n",
            "Key features:\n",
            "  - Sequential and Greedy modes\n",
            "  - Difficulty-based instance routing\n",
            "  - Automatic stopping when no improvement\n",
            "  - Compatible with scikit-learn API\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# ===== DEFINE BASE MODEL CONFIGURATIONS =====\n",
        "# Following the paper's approach with different complexity levels\n",
        "\n",
        "base_configs = {\n",
        "    'simple': [\n",
        "        KNeighborsClassifier(n_neighbors=3),\n",
        "        LogisticRegression(max_iter=1000, random_state=42),\n",
        "        DecisionTreeClassifier(max_depth=5, random_state=42),\n",
        "        GaussianNB()\n",
        "    ],\n",
        "    'advanced': [\n",
        "        RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1),\n",
        "        XGBClassifier(n_estimators=50, max_depth=5, random_state=42, eval_metric='mlogloss'),\n",
        "        MLPClassifier(hidden_layer_sizes=(50,), max_iter=300, random_state=42)  # FIXED\n",
        "    ],\n",
        "    'mixed': [\n",
        "        KNeighborsClassifier(n_neighbors=5),\n",
        "        DecisionTreeClassifier(max_depth=7, random_state=42),\n",
        "        RandomForestClassifier(n_estimators=30, max_depth=8, random_state=42, n_jobs=-1),\n",
        "        XGBClassifier(n_estimators=30, max_depth=3, random_state=42, eval_metric='mlogloss')\n",
        "    ],\n",
        "    'comprehensive': [\n",
        "        KNeighborsClassifier(n_neighbors=3),\n",
        "        KNeighborsClassifier(n_neighbors=5),\n",
        "        LogisticRegression(max_iter=1000, random_state=42),\n",
        "        DecisionTreeClassifier(max_depth=5, random_state=42),\n",
        "        GaussianNB(),\n",
        "        RandomForestClassifier(n_estimators=30, max_depth=8, random_state=42, n_jobs=-1),\n",
        "        XGBClassifier(n_estimators=30, max_depth=3, random_state=42, eval_metric='mlogloss')\n",
        "    ]\n",
        "}\n",
        "\n",
        "# ===== DEFINE ROUTER MODEL CONFIGURATIONS =====\n",
        "router_configs = {\n",
        "    'knn3': KNeighborsClassifier(n_neighbors=3),\n",
        "    'knn5': KNeighborsClassifier(n_neighbors=5),\n",
        "    'rf': RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1),\n",
        "    'mlp': MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=300, random_state=42)  # FIXED\n",
        "}\n",
        "\n",
        "# ===== FUNCTION TO EVALUATE HELLSEMBLE CONFIGURATION =====\n",
        "def evaluate_hellsemble(X_train, y_train, X_test, y_test,\n",
        "                        base_config_name, router_config_name,\n",
        "                        mode='sequential', dataset_name=''):\n",
        "    \"\"\"\n",
        "    Train and evaluate a single Hellsemble configuration\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Dataset: {dataset_name}\")\n",
        "    print(f\"Base Config: {base_config_name} | Router: {router_config_name} | Mode: {mode}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Get configurations\n",
        "    base_models = base_configs[base_config_name]\n",
        "    router_model = router_configs[router_config_name]\n",
        "\n",
        "    # Create and train Hellsemble\n",
        "    hellsemble = Hellsemble(\n",
        "        base_models=base_models,\n",
        "        router_model=router_model,\n",
        "        mode=mode,\n",
        "        alpha=0.3,\n",
        "        val_size=0.2,\n",
        "        metric='balanced_accuracy',  # Better for imbalanced classes\n",
        "        verbose=True,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    hellsemble.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    if hellsemble.n_circles_ > 0:\n",
        "        y_pred = hellsemble.predict(X_test)\n",
        "\n",
        "        # Compute metrics\n",
        "        metrics, cm = compute_per_class_metrics(y_test, y_pred)\n",
        "        test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"TEST SET RESULTS\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Overall Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "        print(f\"\\nConfusion Matrix:\")\n",
        "        print(cm)\n",
        "        print(f\"\\n{'Class':<12} {'Sensitivity':<15} {'Specificity':<15}\")\n",
        "        print(\"-\" * 42)\n",
        "        for class_name, vals in metrics.items():\n",
        "            print(f\"{class_name:<12} {vals['sensitivity']:>6.2f}%{'':<8} {vals['specificity']:>6.2f}%\")\n",
        "\n",
        "        return {\n",
        "            'dataset': dataset_name,\n",
        "            'base_config': base_config_name,\n",
        "            'router': router_config_name,\n",
        "            'mode': mode,\n",
        "            'n_circles': hellsemble.n_circles_,\n",
        "            'accuracy': test_accuracy,\n",
        "            'walk_sens': metrics['Walk']['sensitivity'],\n",
        "            'fog_sens': metrics['FoG']['sensitivity'],\n",
        "            'trans_sens': metrics['Transition']['sensitivity'],\n",
        "            'walk_spec': metrics['Walk']['specificity'],\n",
        "            'fog_spec': metrics['FoG']['specificity'],\n",
        "            'trans_spec': metrics['Transition']['specificity'],\n",
        "            'confusion_matrix': cm\n",
        "        }\n",
        "    else:\n",
        "        print(\" No ensemble was formed (stopped at first iteration)\")\n",
        "        return None\n",
        "\n",
        "# ===== RUN EXPERIMENTS ON ALL DATASETS =====\n",
        "all_hellsemble_results = []\n",
        "\n",
        "# Configurations to test (select subset to avoid too many runs)\n",
        "test_configs = [\n",
        "    ('simple', 'knn3', 'sequential'),\n",
        "    ('simple', 'rf', 'sequential'),\n",
        "    ('simple', 'knn3', 'greedy'),\n",
        "    ('advanced', 'knn3', 'sequential'),\n",
        "    ('advanced', 'rf', 'sequential'),\n",
        "    ('mixed', 'knn5', 'sequential'),\n",
        "    ('mixed', 'rf', 'sequential'),\n",
        "    ('mixed', 'mlp', 'greedy'),\n",
        "    ('comprehensive', 'rf', 'sequential'),\n",
        "    ('comprehensive', 'mlp', 'greedy')\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"HELLSEMBLE EVALUATION ON FOG DATASETS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nTesting {len(test_configs)} configurations on 3 datasets (2s, 3s, 4s)\")\n",
        "print(f\"Total experiments: {len(test_configs) * 3} = {len(test_configs)} configs  3 datasets\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test on 2s dataset with 5 features\n",
        "print(\"\\n\" + \"#\"*70)\n",
        "print(\"# DATASET: 2s WINDOWS, 5 FEATURES\")\n",
        "print(\"#\"*70)\n",
        "\n",
        "X_train_2s, y_train_2s = data_2s['train']['5']\n",
        "X_test_2s, y_test_2s = data_2s['test']['5']\n",
        "\n",
        "for base_cfg, router_cfg, mode in test_configs:\n",
        "    result = evaluate_hellsemble(\n",
        "        X_train_2s, y_train_2s, X_test_2s, y_test_2s,\n",
        "        base_cfg, router_cfg, mode, dataset_name='2s-5feat'\n",
        "    )\n",
        "    if result:\n",
        "        all_hellsemble_results.append(result)\n",
        "\n",
        "# Test on 3s dataset with 15 features\n",
        "print(\"\\n\" + \"#\"*70)\n",
        "print(\"# DATASET: 3s WINDOWS, 15 FEATURES\")\n",
        "print(\"#\"*70)\n",
        "\n",
        "X_train_3s, y_train_3s = data_3s['train']['15']\n",
        "X_test_3s, y_test_3s = data_3s['test']['15']\n",
        "\n",
        "for base_cfg, router_cfg, mode in test_configs:\n",
        "    result = evaluate_hellsemble(\n",
        "        X_train_3s, y_train_3s, X_test_3s, y_test_3s,\n",
        "        base_cfg, router_cfg, mode, dataset_name='3s-15feat'\n",
        "    )\n",
        "    if result:\n",
        "        all_hellsemble_results.append(result)\n",
        "\n",
        "# Test on 4s dataset with 30 features\n",
        "print(\"\\n\" + \"#\"*70)\n",
        "print(\"# DATASET: 4s WINDOWS, 30 FEATURES\")\n",
        "print(\"#\"*70)\n",
        "\n",
        "X_train_4s, y_train_4s = data_4s['train']['30']\n",
        "X_test_4s, y_test_4s = data_4s['test']['30']\n",
        "\n",
        "for base_cfg, router_cfg, mode in test_configs:\n",
        "    result = evaluate_hellsemble(\n",
        "        X_train_4s, y_train_4s, X_test_4s, y_test_4s,\n",
        "        base_cfg, router_cfg, mode, dataset_name='4s-30feat'\n",
        "    )\n",
        "    if result:\n",
        "        all_hellsemble_results.append(result)\n",
        "\n",
        "# ===== SUMMARY OF ALL RESULTS =====\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY: ALL HELLSEMBLE RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "results_df = pd.DataFrame(all_hellsemble_results)\n",
        "\n",
        "print(f\"\\nTotal successful experiments: {len(results_df)}\")\n",
        "print(f\"\\nResults DataFrame:\")\n",
        "print(results_df[['dataset', 'base_config', 'router', 'mode', 'n_circles',\n",
        "                  'accuracy', 'trans_sens', 'fog_sens', 'walk_sens']].to_string(index=False))\n",
        "\n",
        "# ===== BEST CONFIGURATIONS =====\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TOP 5 CONFIGURATIONS BY OVERALL ACCURACY\")\n",
        "print(\"=\"*70)\n",
        "top_accuracy = results_df.nlargest(5, 'accuracy')\n",
        "print(top_accuracy[['dataset', 'base_config', 'router', 'mode', 'n_circles',\n",
        "                    'accuracy', 'trans_sens', 'fog_sens', 'walk_sens']].to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TOP 5 CONFIGURATIONS BY TRANSITION SENSITIVITY\")\n",
        "print(\"=\"*70)\n",
        "top_trans = results_df.nlargest(5, 'trans_sens')\n",
        "print(top_trans[['dataset', 'base_config', 'router', 'mode', 'n_circles',\n",
        "                 'accuracy', 'trans_sens', 'fog_sens', 'walk_sens']].to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONFIGURATIONS WITH BALANCED PERFORMANCE (all classes > 60%)\")\n",
        "print(\"=\"*70)\n",
        "balanced = results_df[\n",
        "    (results_df['trans_sens'] > 60) &\n",
        "    (results_df['fog_sens'] > 60) &\n",
        "    (results_df['walk_sens'] > 60)\n",
        "].sort_values('accuracy', ascending=False)\n",
        "\n",
        "if len(balanced) > 0:\n",
        "    print(balanced[['dataset', 'base_config', 'router', 'mode', 'n_circles',\n",
        "                    'accuracy', 'trans_sens', 'fog_sens', 'walk_sens']].to_string(index=False))\n",
        "else:\n",
        "    print(\"No configurations achieved balanced performance (all classes > 60%)\")\n",
        "\n",
        "# Save results for later comparison\n",
        "hellsemble_results_df = results_df.copy()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" HELLSEMBLE EVALUATION COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nResults saved to 'hellsemble_results_df' DataFrame\")\n",
        "print(f\"Ready for comparison with classical models in next step!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRpcTGgV2rD-",
        "outputId": "29000768-0a2b-4d09-aed8-7554d61d8cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "HELLSEMBLE EVALUATION ON FOG DATASETS\n",
            "======================================================================\n",
            "\n",
            "Testing 10 configurations on 3 datasets (2s, 3s, 4s)\n",
            "Total experiments: 30 = 10 configs  3 datasets\n",
            "======================================================================\n",
            "\n",
            "######################################################################\n",
            "# DATASET: 2s WINDOWS, 5 FEATURES\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "Dataset: 2s-5feat\n",
            "Base Config: simple | Router: knn3 | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 3083\n",
            "Validation samples: 771\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 3083\n",
            "Validation balanced_accuracy: 0.5370\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 546, Correct: 2537\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1307\n",
            "Validation balanced_accuracy: 0.5481\n",
            "Model type: LogisticRegression\n",
            "Misclassified: 588, Correct: 719\n",
            "\n",
            "--- Circle 2 ---\n",
            "Training samples: 803\n",
            "Validation balanced_accuracy: 0.5408\n",
            "Model type: DecisionTreeClassifier\n",
            "Stopping: No improvement (0.5408 <= 0.5481)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 2\n",
            "   Final validation balanced_accuracy: 0.5481\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.6981 (69.81%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[459  53  25]\n",
            " [ 83 179  23]\n",
            " [ 49  58  35]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          85.47%          69.09%\n",
            "FoG           62.81%          83.65%\n",
            "Transition    24.65%          94.16%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 2s-5feat\n",
            "Base Config: simple | Router: rf | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 3083\n",
            "Validation samples: 771\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 3083\n",
            "Validation balanced_accuracy: 0.5370\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 546, Correct: 2537\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1307\n",
            "Validation balanced_accuracy: 0.5370\n",
            "Model type: LogisticRegression\n",
            "Stopping: No improvement (0.5370 <= 0.5370)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.5370\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.6950 (69.50%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[454  52  31]\n",
            " [ 83 176  26]\n",
            " [ 46  56  40]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.54%          69.79%\n",
            "FoG           61.75%          84.09%\n",
            "Transition    28.17%          93.07%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 2s-5feat\n",
            "Base Config: simple | Router: knn3 | Mode: greedy\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (greedy mode)\n",
            "============================================================\n",
            "Initial training samples: 3083\n",
            "Validation samples: 771\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 3083\n",
            "Validation balanced_accuracy: 0.5481\n",
            "Model type: DecisionTreeClassifier\n",
            "Misclassified: 810, Correct: 2273\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1491\n",
            "Validation balanced_accuracy: 0.5551\n",
            "Model type: DecisionTreeClassifier\n",
            "Misclassified: 601, Correct: 890\n",
            "\n",
            "--- Circle 2 ---\n",
            "Training samples: 868\n",
            "Validation balanced_accuracy: 0.5628\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 247, Correct: 621\n",
            "\n",
            "--- Circle 3 ---\n",
            "Training samples: 433\n",
            "Validation balanced_accuracy: 0.5523\n",
            "Model type: KNeighborsClassifier\n",
            "Stopping: No improvement (0.5523 <= 0.5628)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 3\n",
            "   Final validation balanced_accuracy: 0.5628\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7178 (71.78%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[453  79   5]\n",
            " [ 47 235   3]\n",
            " [ 47  91   4]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.36%          77.99%\n",
            "FoG           82.46%          74.96%\n",
            "Transition     2.82%          99.03%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 2s-5feat\n",
            "Base Config: advanced | Router: knn3 | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 3083\n",
            "Validation samples: 771\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 3083\n",
            "Validation balanced_accuracy: 0.5968\n",
            "Model type: RandomForestClassifier\n",
            "Misclassified: 342, Correct: 2741\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1164\n",
            "Validation balanced_accuracy: 0.5960\n",
            "Model type: XGBClassifier\n",
            "Stopping: No improvement (0.5960 <= 0.5968)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.5968\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7427 (74.27%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[456  67  14]\n",
            " [ 33 244   8]\n",
            " [ 38  88  16]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.92%          83.37%\n",
            "FoG           85.61%          77.17%\n",
            "Transition    11.27%          97.32%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 2s-5feat\n",
            "Base Config: advanced | Router: rf | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 3083\n",
            "Validation samples: 771\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 3083\n",
            "Validation balanced_accuracy: 0.5968\n",
            "Model type: RandomForestClassifier\n",
            "Misclassified: 342, Correct: 2741\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1164\n",
            "Validation balanced_accuracy: 0.5953\n",
            "Model type: XGBClassifier\n",
            "Stopping: No improvement (0.5953 <= 0.5968)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.5968\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7427 (74.27%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[456  67  14]\n",
            " [ 33 244   8]\n",
            " [ 38  88  16]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.92%          83.37%\n",
            "FoG           85.61%          77.17%\n",
            "Transition    11.27%          97.32%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 2s-5feat\n",
            "Base Config: mixed | Router: knn5 | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 3083\n",
            "Validation samples: 771\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 3083\n",
            "Validation balanced_accuracy: 0.5473\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 656, Correct: 2427\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1384\n",
            "Validation balanced_accuracy: 0.5414\n",
            "Model type: DecisionTreeClassifier\n",
            "Stopping: No improvement (0.5414 <= 0.5473)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.5473\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.6898 (68.98%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[446  66  25]\n",
            " [ 78 192  15]\n",
            " [ 51  64  27]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          83.05%          69.79%\n",
            "FoG           67.37%          80.85%\n",
            "Transition    19.01%          95.13%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 2s-5feat\n",
            "Base Config: mixed | Router: rf | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 3083\n",
            "Validation samples: 771\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 3083\n",
            "Validation balanced_accuracy: 0.5473\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 656, Correct: 2427\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1384\n",
            "Validation balanced_accuracy: 0.5473\n",
            "Model type: DecisionTreeClassifier\n",
            "Stopping: No improvement (0.5473 <= 0.5473)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.5473\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.6898 (68.98%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[446  66  25]\n",
            " [ 78 192  15]\n",
            " [ 51  64  27]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          83.05%          69.79%\n",
            "FoG           67.37%          80.85%\n",
            "Transition    19.01%          95.13%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 2s-5feat\n",
            "Base Config: mixed | Router: mlp | Mode: greedy\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (greedy mode)\n",
            "============================================================\n",
            "Initial training samples: 3083\n",
            "Validation samples: 771\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 3083\n",
            "Validation balanced_accuracy: 0.5724\n",
            "Model type: RandomForestClassifier\n",
            "Misclassified: 550, Correct: 2533\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1309\n",
            "Validation balanced_accuracy: 0.5724\n",
            "Model type: KNeighborsClassifier\n",
            "Stopping: No improvement (0.5724 <= 0.5724)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.5724\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7355 (73.55%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[455  72  10]\n",
            " [ 42 240   3]\n",
            " [ 37  91  14]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.73%          81.50%\n",
            "FoG           84.21%          75.99%\n",
            "Transition     9.86%          98.42%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 2s-5feat\n",
            "Base Config: comprehensive | Router: rf | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 3083\n",
            "Validation samples: 771\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 3083\n",
            "Validation balanced_accuracy: 0.5370\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 546, Correct: 2537\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1307\n",
            "Validation balanced_accuracy: 0.5370\n",
            "Model type: KNeighborsClassifier\n",
            "Stopping: No improvement (0.5370 <= 0.5370)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.5370\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.6950 (69.50%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[454  52  31]\n",
            " [ 83 176  26]\n",
            " [ 46  56  40]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.54%          69.79%\n",
            "FoG           61.75%          84.09%\n",
            "Transition    28.17%          93.07%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 2s-5feat\n",
            "Base Config: comprehensive | Router: mlp | Mode: greedy\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (greedy mode)\n",
            "============================================================\n",
            "Initial training samples: 3083\n",
            "Validation samples: 771\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 3083\n",
            "Validation balanced_accuracy: 0.5724\n",
            "Model type: RandomForestClassifier\n",
            "Misclassified: 550, Correct: 2533\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1309\n",
            "Validation balanced_accuracy: 0.5724\n",
            "Model type: KNeighborsClassifier\n",
            "Stopping: No improvement (0.5724 <= 0.5724)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.5724\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7355 (73.55%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[455  72  10]\n",
            " [ 42 240   3]\n",
            " [ 37  91  14]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.73%          81.50%\n",
            "FoG           84.21%          75.99%\n",
            "Transition     9.86%          98.42%\n",
            "\n",
            "######################################################################\n",
            "# DATASET: 3s WINDOWS, 15 FEATURES\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "Dataset: 3s-15feat\n",
            "Base Config: simple | Router: knn3 | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 2374\n",
            "Validation samples: 594\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 2374\n",
            "Validation balanced_accuracy: 0.6548\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 300, Correct: 2074\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 922\n",
            "Validation balanced_accuracy: 0.6417\n",
            "Model type: LogisticRegression\n",
            "Stopping: No improvement (0.6417 <= 0.6548)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.6548\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7251 (72.51%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[243  39  34]\n",
            " [ 33 228  23]\n",
            " [ 29  46  67]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          76.90%          85.45%\n",
            "FoG           80.28%          81.44%\n",
            "Transition    47.18%          90.50%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 3s-15feat\n",
            "Base Config: simple | Router: rf | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 2374\n",
            "Validation samples: 594\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 2374\n",
            "Validation balanced_accuracy: 0.6548\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 300, Correct: 2074\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 922\n",
            "Validation balanced_accuracy: 0.6548\n",
            "Model type: LogisticRegression\n",
            "Stopping: No improvement (0.6548 <= 0.6548)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.6548\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7251 (72.51%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[243  39  34]\n",
            " [ 33 228  23]\n",
            " [ 29  46  67]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          76.90%          85.45%\n",
            "FoG           80.28%          81.44%\n",
            "Transition    47.18%          90.50%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 3s-15feat\n",
            "Base Config: simple | Router: knn3 | Mode: greedy\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (greedy mode)\n",
            "============================================================\n",
            "Initial training samples: 2374\n",
            "Validation samples: 594\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 2374\n",
            "Validation balanced_accuracy: 0.6548\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 300, Correct: 2074\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 922\n",
            "Validation balanced_accuracy: 0.6552\n",
            "Model type: GaussianNB\n",
            "Misclassified: 473, Correct: 449\n",
            "\n",
            "--- Circle 2 ---\n",
            "Training samples: 607\n",
            "Validation balanced_accuracy: 0.6534\n",
            "Model type: KNeighborsClassifier\n",
            "Stopping: No improvement (0.6534 <= 0.6552)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 2\n",
            "   Final validation balanced_accuracy: 0.6552\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7143 (71.43%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[234  41  41]\n",
            " [ 32 225  27]\n",
            " [ 25  46  71]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          74.05%          86.62%\n",
            "FoG           79.23%          81.00%\n",
            "Transition    50.00%          88.67%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 3s-15feat\n",
            "Base Config: advanced | Router: knn3 | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 2374\n",
            "Validation samples: 594\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 2374\n",
            "Validation balanced_accuracy: 0.6978\n",
            "Model type: RandomForestClassifier\n",
            "Misclassified: 153, Correct: 2221\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 819\n",
            "Validation balanced_accuracy: 0.6934\n",
            "Model type: XGBClassifier\n",
            "Stopping: No improvement (0.6934 <= 0.6978)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.6978\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7668 (76.68%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[264  27  25]\n",
            " [ 16 253  15]\n",
            " [ 33  57  52]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          83.54%          88.50%\n",
            "FoG           89.08%          81.66%\n",
            "Transition    36.62%          93.33%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 3s-15feat\n",
            "Base Config: advanced | Router: rf | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 2374\n",
            "Validation samples: 594\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 2374\n",
            "Validation balanced_accuracy: 0.6978\n",
            "Model type: RandomForestClassifier\n",
            "Misclassified: 153, Correct: 2221\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 819\n",
            "Validation balanced_accuracy: 0.6978\n",
            "Model type: XGBClassifier\n",
            "Stopping: No improvement (0.6978 <= 0.6978)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.6978\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7668 (76.68%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[264  27  25]\n",
            " [ 16 253  15]\n",
            " [ 33  57  52]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          83.54%          88.50%\n",
            "FoG           89.08%          81.66%\n",
            "Transition    36.62%          93.33%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 3s-15feat\n",
            "Base Config: mixed | Router: knn5 | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 2374\n",
            "Validation samples: 594\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 2374\n",
            "Validation balanced_accuracy: 0.6436\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 431, Correct: 1943\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1013\n",
            "Validation balanced_accuracy: 0.6511\n",
            "Model type: DecisionTreeClassifier\n",
            "Misclassified: 234, Correct: 779\n",
            "\n",
            "--- Circle 2 ---\n",
            "Training samples: 467\n",
            "Validation balanced_accuracy: 0.6407\n",
            "Model type: RandomForestClassifier\n",
            "Stopping: No improvement (0.6407 <= 0.6511)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 2\n",
            "   Final validation balanced_accuracy: 0.6511\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7170 (71.70%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[239  51  26]\n",
            " [ 28 230  26]\n",
            " [ 28  51  63]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          75.63%          86.85%\n",
            "FoG           80.99%          77.73%\n",
            "Transition    44.37%          91.33%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 3s-15feat\n",
            "Base Config: mixed | Router: rf | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 2374\n",
            "Validation samples: 594\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 2374\n",
            "Validation balanced_accuracy: 0.6436\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 431, Correct: 1943\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1013\n",
            "Validation balanced_accuracy: 0.6436\n",
            "Model type: DecisionTreeClassifier\n",
            "Stopping: No improvement (0.6436 <= 0.6436)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.6436\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7129 (71.29%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[239  51  26]\n",
            " [ 30 229  25]\n",
            " [ 29  52  61]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          75.63%          86.15%\n",
            "FoG           80.63%          77.51%\n",
            "Transition    42.96%          91.50%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 3s-15feat\n",
            "Base Config: mixed | Router: mlp | Mode: greedy\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (greedy mode)\n",
            "============================================================\n",
            "Initial training samples: 2374\n",
            "Validation samples: 594\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 2374\n",
            "Validation balanced_accuracy: 0.6918\n",
            "Model type: XGBClassifier\n",
            "Misclassified: 434, Correct: 1940\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1016\n",
            "Validation balanced_accuracy: 0.6947\n",
            "Model type: RandomForestClassifier\n",
            "Misclassified: 76, Correct: 940\n",
            "\n",
            "--- Circle 2 ---\n",
            "Training samples: 358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation balanced_accuracy: 0.6987\n",
            "Model type: XGBClassifier\n",
            "Misclassified: 21, Correct: 337\n",
            "\n",
            "--- Circle 3 ---\n",
            "Training samples: 122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation balanced_accuracy: 0.6960\n",
            "Model type: KNeighborsClassifier\n",
            "Stopping: No improvement (0.6960 <= 0.6987)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 3\n",
            "   Final validation balanced_accuracy: 0.6987\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7466 (74.66%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[258  33  25]\n",
            " [ 18 241  25]\n",
            " [ 31  56  55]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          81.65%          88.50%\n",
            "FoG           84.86%          80.57%\n",
            "Transition    38.73%          91.67%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 3s-15feat\n",
            "Base Config: comprehensive | Router: rf | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 2374\n",
            "Validation samples: 594\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 2374\n",
            "Validation balanced_accuracy: 0.6548\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 300, Correct: 2074\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 922\n",
            "Validation balanced_accuracy: 0.6548\n",
            "Model type: KNeighborsClassifier\n",
            "Stopping: No improvement (0.6548 <= 0.6548)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.6548\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7251 (72.51%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[243  39  34]\n",
            " [ 33 228  23]\n",
            " [ 29  46  67]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          76.90%          85.45%\n",
            "FoG           80.28%          81.44%\n",
            "Transition    47.18%          90.50%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 3s-15feat\n",
            "Base Config: comprehensive | Router: mlp | Mode: greedy\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (greedy mode)\n",
            "============================================================\n",
            "Initial training samples: 2374\n",
            "Validation samples: 594\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 2374\n",
            "Validation balanced_accuracy: 0.6918\n",
            "Model type: XGBClassifier\n",
            "Misclassified: 434, Correct: 1940\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 1016\n",
            "Validation balanced_accuracy: 0.6947\n",
            "Model type: RandomForestClassifier\n",
            "Misclassified: 76, Correct: 940\n",
            "\n",
            "--- Circle 2 ---\n",
            "Training samples: 358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation balanced_accuracy: 0.6987\n",
            "Model type: DecisionTreeClassifier\n",
            "Misclassified: 138, Correct: 220\n",
            "\n",
            "--- Circle 3 ---\n",
            "Training samples: 204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation balanced_accuracy: 0.7002\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 67, Correct: 137\n",
            "\n",
            "--- Circle 4 ---\n",
            "Training samples: 108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation balanced_accuracy: 0.7003\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 58, Correct: 50\n",
            "\n",
            "--- Circle 5 ---\n",
            "Training samples: 73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation balanced_accuracy: 0.6960\n",
            "Model type: DecisionTreeClassifier\n",
            "Stopping: No improvement (0.6960 <= 0.7003)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 5\n",
            "   Final validation balanced_accuracy: 0.7003\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7439 (74.39%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[256  31  29]\n",
            " [ 19 240  25]\n",
            " [ 31  55  56]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          81.01%          88.26%\n",
            "FoG           84.51%          81.22%\n",
            "Transition    39.44%          91.00%\n",
            "\n",
            "######################################################################\n",
            "# DATASET: 4s WINDOWS, 30 FEATURES\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "Dataset: 4s-30feat\n",
            "Base Config: simple | Router: knn3 | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 1783\n",
            "Validation samples: 446\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 1783\n",
            "Validation balanced_accuracy: 0.7609\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 239, Correct: 1544\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 702\n",
            "Validation balanced_accuracy: 0.7609\n",
            "Model type: LogisticRegression\n",
            "Stopping: No improvement (0.7609 <= 0.7609)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.7609\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7867 (78.67%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[172  21  15]\n",
            " [ 10 179  19]\n",
            " [ 29  25  88]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          82.69%          88.86%\n",
            "FoG           86.06%          86.86%\n",
            "Transition    61.97%          91.83%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 4s-30feat\n",
            "Base Config: simple | Router: rf | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 1783\n",
            "Validation samples: 446\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 1783\n",
            "Validation balanced_accuracy: 0.7609\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 239, Correct: 1544\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 702\n",
            "Validation balanced_accuracy: 0.7609\n",
            "Model type: LogisticRegression\n",
            "Stopping: No improvement (0.7609 <= 0.7609)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.7609\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7867 (78.67%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[172  21  15]\n",
            " [ 10 179  19]\n",
            " [ 29  25  88]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          82.69%          88.86%\n",
            "FoG           86.06%          86.86%\n",
            "Transition    61.97%          91.83%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 4s-30feat\n",
            "Base Config: simple | Router: knn3 | Mode: greedy\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (greedy mode)\n",
            "============================================================\n",
            "Initial training samples: 1783\n",
            "Validation samples: 446\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 1783\n",
            "Validation balanced_accuracy: 0.7609\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 239, Correct: 1544\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 702\n",
            "Validation balanced_accuracy: 0.7609\n",
            "Model type: KNeighborsClassifier\n",
            "Stopping: No improvement (0.7609 <= 0.7609)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.7609\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7867 (78.67%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[172  21  15]\n",
            " [ 10 179  19]\n",
            " [ 29  25  88]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          82.69%          88.86%\n",
            "FoG           86.06%          86.86%\n",
            "Transition    61.97%          91.83%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 4s-30feat\n",
            "Base Config: advanced | Router: knn3 | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 1783\n",
            "Validation samples: 446\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 1783\n",
            "Validation balanced_accuracy: 0.7486\n",
            "Model type: RandomForestClassifier\n",
            "Misclassified: 58, Correct: 1725\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 575\n",
            "Validation balanced_accuracy: 0.7486\n",
            "Model type: XGBClassifier\n",
            "Stopping: No improvement (0.7486 <= 0.7486)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.7486\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.8082 (80.82%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[176  18  14]\n",
            " [  3 189  16]\n",
            " [ 27  29  86]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.62%          91.43%\n",
            "FoG           90.87%          86.57%\n",
            "Transition    60.56%          92.79%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 4s-30feat\n",
            "Base Config: advanced | Router: rf | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 1783\n",
            "Validation samples: 446\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 1783\n",
            "Validation balanced_accuracy: 0.7486\n",
            "Model type: RandomForestClassifier\n",
            "Misclassified: 58, Correct: 1725\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 575\n",
            "Validation balanced_accuracy: 0.7486\n",
            "Model type: XGBClassifier\n",
            "Stopping: No improvement (0.7486 <= 0.7486)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.7486\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.8082 (80.82%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[176  18  14]\n",
            " [  3 189  16]\n",
            " [ 27  29  86]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          84.62%          91.43%\n",
            "FoG           90.87%          86.57%\n",
            "Transition    60.56%          92.79%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 4s-30feat\n",
            "Base Config: mixed | Router: knn5 | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 1783\n",
            "Validation samples: 446\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 1783\n",
            "Validation balanced_accuracy: 0.7547\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 301, Correct: 1482\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 745\n",
            "Validation balanced_accuracy: 0.7547\n",
            "Model type: DecisionTreeClassifier\n",
            "Stopping: No improvement (0.7547 <= 0.7547)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.7547\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7903 (79.03%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[168  19  21]\n",
            " [  3 185  20]\n",
            " [ 29  25  88]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          80.77%          90.86%\n",
            "FoG           88.94%          87.43%\n",
            "Transition    61.97%          90.14%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 4s-30feat\n",
            "Base Config: mixed | Router: rf | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 1783\n",
            "Validation samples: 446\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 1783\n",
            "Validation balanced_accuracy: 0.7547\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 301, Correct: 1482\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 745\n",
            "Validation balanced_accuracy: 0.7547\n",
            "Model type: DecisionTreeClassifier\n",
            "Stopping: No improvement (0.7547 <= 0.7547)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.7547\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7903 (79.03%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[168  19  21]\n",
            " [  3 185  20]\n",
            " [ 29  25  88]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          80.77%          90.86%\n",
            "FoG           88.94%          87.43%\n",
            "Transition    61.97%          90.14%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 4s-30feat\n",
            "Base Config: mixed | Router: mlp | Mode: greedy\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (greedy mode)\n",
            "============================================================\n",
            "Initial training samples: 1783\n",
            "Validation samples: 446\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 1783\n",
            "Validation balanced_accuracy: 0.7547\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 301, Correct: 1482\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation balanced_accuracy: 0.7587\n",
            "Model type: RandomForestClassifier\n",
            "Misclassified: 48, Correct: 697\n",
            "\n",
            "--- Circle 2 ---\n",
            "Training samples: 257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation balanced_accuracy: 0.7565\n",
            "Model type: RandomForestClassifier\n",
            "Stopping: No improvement (0.7565 <= 0.7587)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 2\n",
            "   Final validation balanced_accuracy: 0.7587\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7885 (78.85%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[170  16  22]\n",
            " [  3 184  21]\n",
            " [ 31  25  86]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          81.73%          90.29%\n",
            "FoG           88.46%          88.29%\n",
            "Transition    60.56%          89.66%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 4s-30feat\n",
            "Base Config: comprehensive | Router: rf | Mode: sequential\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (sequential mode)\n",
            "============================================================\n",
            "Initial training samples: 1783\n",
            "Validation samples: 446\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 1783\n",
            "Validation balanced_accuracy: 0.7609\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 239, Correct: 1544\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 702\n",
            "Validation balanced_accuracy: 0.7609\n",
            "Model type: KNeighborsClassifier\n",
            "Stopping: No improvement (0.7609 <= 0.7609)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.7609\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7867 (78.67%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[172  21  15]\n",
            " [ 10 179  19]\n",
            " [ 29  25  88]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          82.69%          88.86%\n",
            "FoG           86.06%          86.86%\n",
            "Transition    61.97%          91.83%\n",
            "\n",
            "======================================================================\n",
            "Dataset: 4s-30feat\n",
            "Base Config: comprehensive | Router: mlp | Mode: greedy\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "Training Hellsemble (greedy mode)\n",
            "============================================================\n",
            "Initial training samples: 1783\n",
            "Validation samples: 446\n",
            "\n",
            "--- Circle 0 ---\n",
            "Training samples: 1783\n",
            "Validation balanced_accuracy: 0.7609\n",
            "Model type: KNeighborsClassifier\n",
            "Misclassified: 239, Correct: 1544\n",
            "\n",
            "--- Circle 1 ---\n",
            "Training samples: 702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation balanced_accuracy: 0.7609\n",
            "Model type: KNeighborsClassifier\n",
            "Stopping: No improvement (0.7609 <= 0.7609)\n",
            "\n",
            "============================================================\n",
            " Training complete!\n",
            "   Total circles: 1\n",
            "   Final validation balanced_accuracy: 0.7609\n",
            "============================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST SET RESULTS\n",
            "======================================================================\n",
            "Overall Accuracy: 0.7867 (78.67%)\n",
            "\n",
            "Confusion Matrix:\n",
            "[[172  21  15]\n",
            " [ 10 179  19]\n",
            " [ 29  25  88]]\n",
            "\n",
            "Class        Sensitivity     Specificity    \n",
            "------------------------------------------\n",
            "Walk          82.69%          88.86%\n",
            "FoG           86.06%          86.86%\n",
            "Transition    61.97%          91.83%\n",
            "\n",
            "======================================================================\n",
            "SUMMARY: ALL HELLSEMBLE RESULTS\n",
            "======================================================================\n",
            "\n",
            "Total successful experiments: 30\n",
            "\n",
            "Results DataFrame:\n",
            "  dataset   base_config router       mode  n_circles  accuracy  trans_sens  fog_sens  walk_sens\n",
            " 2s-5feat        simple   knn3 sequential          2  0.698133   24.647887 62.807018  85.474860\n",
            " 2s-5feat        simple     rf sequential          1  0.695021   28.169014 61.754386  84.543762\n",
            " 2s-5feat        simple   knn3     greedy          3  0.717842    2.816901 82.456140  84.357542\n",
            " 2s-5feat      advanced   knn3 sequential          1  0.742739   11.267606 85.614035  84.916201\n",
            " 2s-5feat      advanced     rf sequential          1  0.742739   11.267606 85.614035  84.916201\n",
            " 2s-5feat         mixed   knn5 sequential          1  0.689834   19.014085 67.368421  83.054004\n",
            " 2s-5feat         mixed     rf sequential          1  0.689834   19.014085 67.368421  83.054004\n",
            " 2s-5feat         mixed    mlp     greedy          1  0.735477    9.859155 84.210526  84.729981\n",
            " 2s-5feat comprehensive     rf sequential          1  0.695021   28.169014 61.754386  84.543762\n",
            " 2s-5feat comprehensive    mlp     greedy          1  0.735477    9.859155 84.210526  84.729981\n",
            "3s-15feat        simple   knn3 sequential          1  0.725067   47.183099 80.281690  76.898734\n",
            "3s-15feat        simple     rf sequential          1  0.725067   47.183099 80.281690  76.898734\n",
            "3s-15feat        simple   knn3     greedy          2  0.714286   50.000000 79.225352  74.050633\n",
            "3s-15feat      advanced   knn3 sequential          1  0.766846   36.619718 89.084507  83.544304\n",
            "3s-15feat      advanced     rf sequential          1  0.766846   36.619718 89.084507  83.544304\n",
            "3s-15feat         mixed   knn5 sequential          2  0.716981   44.366197 80.985915  75.632911\n",
            "3s-15feat         mixed     rf sequential          1  0.712938   42.957746 80.633803  75.632911\n",
            "3s-15feat         mixed    mlp     greedy          3  0.746631   38.732394 84.859155  81.645570\n",
            "3s-15feat comprehensive     rf sequential          1  0.725067   47.183099 80.281690  76.898734\n",
            "3s-15feat comprehensive    mlp     greedy          5  0.743935   39.436620 84.507042  81.012658\n",
            "4s-30feat        simple   knn3 sequential          1  0.786738   61.971831 86.057692  82.692308\n",
            "4s-30feat        simple     rf sequential          1  0.786738   61.971831 86.057692  82.692308\n",
            "4s-30feat        simple   knn3     greedy          1  0.786738   61.971831 86.057692  82.692308\n",
            "4s-30feat      advanced   knn3 sequential          1  0.808244   60.563380 90.865385  84.615385\n",
            "4s-30feat      advanced     rf sequential          1  0.808244   60.563380 90.865385  84.615385\n",
            "4s-30feat         mixed   knn5 sequential          1  0.790323   61.971831 88.942308  80.769231\n",
            "4s-30feat         mixed     rf sequential          1  0.790323   61.971831 88.942308  80.769231\n",
            "4s-30feat         mixed    mlp     greedy          2  0.788530   60.563380 88.461538  81.730769\n",
            "4s-30feat comprehensive     rf sequential          1  0.786738   61.971831 86.057692  82.692308\n",
            "4s-30feat comprehensive    mlp     greedy          1  0.786738   61.971831 86.057692  82.692308\n",
            "\n",
            "======================================================================\n",
            "TOP 5 CONFIGURATIONS BY OVERALL ACCURACY\n",
            "======================================================================\n",
            "  dataset base_config router       mode  n_circles  accuracy  trans_sens  fog_sens  walk_sens\n",
            "4s-30feat    advanced   knn3 sequential          1  0.808244   60.563380 90.865385  84.615385\n",
            "4s-30feat    advanced     rf sequential          1  0.808244   60.563380 90.865385  84.615385\n",
            "4s-30feat       mixed   knn5 sequential          1  0.790323   61.971831 88.942308  80.769231\n",
            "4s-30feat       mixed     rf sequential          1  0.790323   61.971831 88.942308  80.769231\n",
            "4s-30feat       mixed    mlp     greedy          2  0.788530   60.563380 88.461538  81.730769\n",
            "\n",
            "======================================================================\n",
            "TOP 5 CONFIGURATIONS BY TRANSITION SENSITIVITY\n",
            "======================================================================\n",
            "  dataset base_config router       mode  n_circles  accuracy  trans_sens  fog_sens  walk_sens\n",
            "4s-30feat      simple   knn3 sequential          1  0.786738   61.971831 86.057692  82.692308\n",
            "4s-30feat      simple     rf sequential          1  0.786738   61.971831 86.057692  82.692308\n",
            "4s-30feat      simple   knn3     greedy          1  0.786738   61.971831 86.057692  82.692308\n",
            "4s-30feat       mixed   knn5 sequential          1  0.790323   61.971831 88.942308  80.769231\n",
            "4s-30feat       mixed     rf sequential          1  0.790323   61.971831 88.942308  80.769231\n",
            "\n",
            "======================================================================\n",
            "CONFIGURATIONS WITH BALANCED PERFORMANCE (all classes > 60%)\n",
            "======================================================================\n",
            "  dataset   base_config router       mode  n_circles  accuracy  trans_sens  fog_sens  walk_sens\n",
            "4s-30feat      advanced     rf sequential          1  0.808244   60.563380 90.865385  84.615385\n",
            "4s-30feat      advanced   knn3 sequential          1  0.808244   60.563380 90.865385  84.615385\n",
            "4s-30feat         mixed   knn5 sequential          1  0.790323   61.971831 88.942308  80.769231\n",
            "4s-30feat         mixed     rf sequential          1  0.790323   61.971831 88.942308  80.769231\n",
            "4s-30feat         mixed    mlp     greedy          2  0.788530   60.563380 88.461538  81.730769\n",
            "4s-30feat        simple   knn3 sequential          1  0.786738   61.971831 86.057692  82.692308\n",
            "4s-30feat        simple     rf sequential          1  0.786738   61.971831 86.057692  82.692308\n",
            "4s-30feat        simple   knn3     greedy          1  0.786738   61.971831 86.057692  82.692308\n",
            "4s-30feat comprehensive     rf sequential          1  0.786738   61.971831 86.057692  82.692308\n",
            "4s-30feat comprehensive    mlp     greedy          1  0.786738   61.971831 86.057692  82.692308\n",
            "\n",
            "======================================================================\n",
            " HELLSEMBLE EVALUATION COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "Results saved to 'hellsemble_results_df' DataFrame\n",
            "Ready for comparison with classical models in next step!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPREHENSIVE COMPARISON: HELLSEMBLE VS CLASSICAL MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ===== COLLECT ALL CLASSICAL MODEL RESULTS =====\n",
        "# We'll extract results from your earlier experiments (results_2s_5feat, results_3s_15feat, results_4s_30feat)\n",
        "\n",
        "classical_results = []\n",
        "\n",
        "# From your earlier runs, we need to extract the results\n",
        "# Let me create a function to properly structure the classical results\n",
        "\n",
        "def extract_classical_results(results_dict, dataset_name):\n",
        "    \"\"\"Extract results from classical model evaluation dictionaries\"\"\"\n",
        "    extracted = []\n",
        "    for model_name, result in results_dict.items():\n",
        "        metrics = result['metrics']\n",
        "        extracted.append({\n",
        "            'dataset': dataset_name,\n",
        "            'model_type': 'Classical',\n",
        "            'model': model_name,\n",
        "            'accuracy': result['test_accuracy'],\n",
        "            'trans_sens': metrics['Transition']['sensitivity'],\n",
        "            'fog_sens': metrics['FoG']['sensitivity'],\n",
        "            'walk_sens': metrics['Walk']['sensitivity'],\n",
        "            'trans_spec': metrics['Transition']['specificity'],\n",
        "            'fog_spec': metrics['FoG']['specificity'],\n",
        "            'walk_spec': metrics['Walk']['specificity']\n",
        "        })\n",
        "    return extracted\n",
        "\n",
        "# Extract classical results from your previous experiments\n",
        "print(\"\\n Extracting classical model results from previous experiments...\")\n",
        "\n",
        "# You ran these earlier - we'll use the stored results\n",
        "# results_2s_5feat, results_3s_15feat, results_4s_30feat\n",
        "\n",
        "classical_2s = extract_classical_results(results_2s_5feat, '2s-5feat')\n",
        "classical_3s = extract_classical_results(results_3s_15feat, '3s-15feat')\n",
        "classical_4s = extract_classical_results(results_4s_30feat, '4s-30feat')\n",
        "\n",
        "all_classical = classical_2s + classical_3s + classical_4s\n",
        "classical_df = pd.DataFrame(all_classical)\n",
        "\n",
        "print(f\" Extracted {len(classical_df)} classical model results\")\n",
        "\n",
        "# ===== PREPARE HELLSEMBLE RESULTS =====\n",
        "hellsemble_df_formatted = hellsemble_results_df.copy()\n",
        "hellsemble_df_formatted['model_type'] = 'Hellsemble'\n",
        "hellsemble_df_formatted['model'] = (hellsemble_df_formatted['base_config'] + '_' +\n",
        "                                     hellsemble_df_formatted['router'] + '_' +\n",
        "                                     hellsemble_df_formatted['mode'])\n",
        "\n",
        "# Add specificity columns (they exist in hellsemble_results_df)\n",
        "hellsemble_comparison = hellsemble_df_formatted[['dataset', 'model_type', 'model', 'accuracy',\n",
        "                                                   'trans_sens', 'fog_sens', 'walk_sens',\n",
        "                                                   'trans_spec', 'fog_spec', 'walk_spec']]\n",
        "\n",
        "print(f\" Prepared {len(hellsemble_comparison)} Hellsemble results\")\n",
        "\n",
        "# ===== COMBINE ALL RESULTS =====\n",
        "all_results = pd.concat([classical_df, hellsemble_comparison], ignore_index=True)\n",
        "\n",
        "print(f\"\\n Total experiments: {len(all_results)}\")\n",
        "print(f\"   Classical: {len(classical_df)}\")\n",
        "print(f\"   Hellsemble: {len(hellsemble_comparison)}\")\n",
        "\n",
        "# ===== COMPARISON 1: BEST MODELS BY DATASET =====\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARISON 1: BEST OVERALL ACCURACY BY DATASET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for dataset in ['2s-5feat', '3s-15feat', '4s-30feat']:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Dataset: {dataset}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    dataset_results = all_results[all_results['dataset'] == dataset].copy()\n",
        "    top_5 = dataset_results.nlargest(5, 'accuracy')\n",
        "\n",
        "    print(\"\\nTop 5 Models:\")\n",
        "    print(f\"{'Rank':<6} {'Type':<12} {'Model':<30} {'Acc%':<8} {'Trans%':<8} {'FoG%':<8} {'Walk%':<8}\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    for idx, (_, row) in enumerate(top_5.iterrows(), 1):\n",
        "        model_name = row['model'][:28] if len(row['model']) > 28 else row['model']\n",
        "        print(f\"{idx:<6} {row['model_type']:<12} {model_name:<30} \"\n",
        "              f\"{row['accuracy']*100:>6.2f}%  {row['trans_sens']:>6.2f}%  \"\n",
        "              f\"{row['fog_sens']:>6.2f}%  {row['walk_sens']:>6.2f}%\")\n",
        "\n",
        "# ===== COMPARISON 2: BEST TRANSITION SENSITIVITY =====\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARISON 2: BEST TRANSITION CLASS SENSITIVITY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for dataset in ['2s-5feat', '3s-15feat', '4s-30feat']:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Dataset: {dataset}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    dataset_results = all_results[all_results['dataset'] == dataset].copy()\n",
        "    top_5 = dataset_results.nlargest(5, 'trans_sens')\n",
        "\n",
        "    print(\"\\nTop 5 Models for Transition Detection:\")\n",
        "    print(f\"{'Rank':<6} {'Type':<12} {'Model':<30} {'Trans%':<8} {'FoG%':<8} {'Walk%':<8} {'Acc%':<8}\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    for idx, (_, row) in enumerate(top_5.iterrows(), 1):\n",
        "        model_name = row['model'][:28] if len(row['model']) > 28 else row['model']\n",
        "        print(f\"{idx:<6} {row['model_type']:<12} {model_name:<30} \"\n",
        "              f\"{row['trans_sens']:>6.2f}%  {row['fog_sens']:>6.2f}%  \"\n",
        "              f\"{row['walk_sens']:>6.2f}%  {row['accuracy']*100:>6.2f}%\")\n",
        "\n",
        "# ===== COMPARISON 3: AVERAGE PERFORMANCE BY MODEL TYPE =====\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARISON 3: AVERAGE PERFORMANCE - CLASSICAL VS HELLSEMBLE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "avg_by_type = all_results.groupby('model_type').agg({\n",
        "    'accuracy': 'mean',\n",
        "    'trans_sens': 'mean',\n",
        "    'fog_sens': 'mean',\n",
        "    'walk_sens': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "print(\"\\nAverage Performance:\")\n",
        "print(avg_by_type)\n",
        "\n",
        "# ===== COMPARISON 4: BEST OF BEST =====\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARISON 4: OVERALL CHAMPIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n OVERALL BEST ACCURACY:\")\n",
        "best_acc = all_results.nlargest(3, 'accuracy')\n",
        "for idx, (_, row) in enumerate(best_acc.iterrows(), 1):\n",
        "    print(f\"{idx}. [{row['model_type']}] {row['model']} on {row['dataset']}: \"\n",
        "          f\"{row['accuracy']*100:.2f}% (Trans: {row['trans_sens']:.2f}%)\")\n",
        "\n",
        "print(\"\\n OVERALL BEST TRANSITION SENSITIVITY:\")\n",
        "best_trans = all_results.nlargest(3, 'trans_sens')\n",
        "for idx, (_, row) in enumerate(best_trans.iterrows(), 1):\n",
        "    print(f\"{idx}. [{row['model_type']}] {row['model']} on {row['dataset']}: \"\n",
        "          f\"{row['trans_sens']:.2f}% (Acc: {row['accuracy']*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n MOST BALANCED PERFORMANCE (all classes > 60%):\")\n",
        "balanced = all_results[\n",
        "    (all_results['trans_sens'] > 60) &\n",
        "    (all_results['fog_sens'] > 60) &\n",
        "    (all_results['walk_sens'] > 60)\n",
        "].sort_values('accuracy', ascending=False).head(5)\n",
        "\n",
        "if len(balanced) > 0:\n",
        "    for idx, (_, row) in enumerate(balanced.iterrows(), 1):\n",
        "        print(f\"{idx}. [{row['model_type']}] {row['model']} on {row['dataset']}: \"\n",
        "              f\"Acc {row['accuracy']*100:.2f}% | Trans {row['trans_sens']:.2f}% | \"\n",
        "              f\"FoG {row['fog_sens']:.2f}% | Walk {row['walk_sens']:.2f}%\")\n",
        "else:\n",
        "    print(\"No models achieved balanced performance (all classes > 60%)\")\n",
        "\n",
        "# ===== COMPARISON 5: DIRECT MATCHUPS =====\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARISON 5: DIRECT MATCHUP - BEST CLASSICAL VS BEST HELLSEMBLE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for dataset in ['2s-5feat', '3s-15feat', '4s-30feat']:\n",
        "    print(f\"\\n{dataset.upper()}:\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    dataset_results = all_results[all_results['dataset'] == dataset]\n",
        "\n",
        "    best_classical = dataset_results[dataset_results['model_type'] == 'Classical'].nlargest(1, 'accuracy').iloc[0]\n",
        "    best_hellsemble = dataset_results[dataset_results['model_type'] == 'Hellsemble'].nlargest(1, 'accuracy').iloc[0]\n",
        "\n",
        "    print(f\"\\n{'Metric':<20} {'Classical Best':<30} {'Hellsemble Best':<30} {'Winner':<15}\")\n",
        "    print(\"-\"*95)\n",
        "\n",
        "    metrics = [\n",
        "        ('Model', best_classical['model'][:28], best_hellsemble['model'][:28], '-'),\n",
        "        ('Accuracy', f\"{best_classical['accuracy']*100:.2f}%\", f\"{best_hellsemble['accuracy']*100:.2f}%\",\n",
        "         'Classical' if best_classical['accuracy'] > best_hellsemble['accuracy'] else 'Hellsemble'),\n",
        "        ('Trans Sensitivity', f\"{best_classical['trans_sens']:.2f}%\", f\"{best_hellsemble['trans_sens']:.2f}%\",\n",
        "         'Classical' if best_classical['trans_sens'] > best_hellsemble['trans_sens'] else 'Hellsemble'),\n",
        "        ('FoG Sensitivity', f\"{best_classical['fog_sens']:.2f}%\", f\"{best_hellsemble['fog_sens']:.2f}%\",\n",
        "         'Classical' if best_classical['fog_sens'] > best_hellsemble['fog_sens'] else 'Hellsemble'),\n",
        "        ('Walk Sensitivity', f\"{best_classical['walk_sens']:.2f}%\", f\"{best_hellsemble['walk_sens']:.2f}%\",\n",
        "         'Classical' if best_classical['walk_sens'] > best_hellsemble['walk_sens'] else 'Hellsemble'),\n",
        "    ]\n",
        "\n",
        "    for metric_name, classical_val, hellsemble_val, winner in metrics:\n",
        "        print(f\"{metric_name:<20} {classical_val:<30} {hellsemble_val:<30} {winner:<15}\")\n",
        "\n",
        "# ===== VISUALIZATION: PERFORMANCE COMPARISON =====\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GENERATING VISUALIZATIONS...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Hellsemble vs Classical Models - Performance Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Plot 1: Accuracy Distribution\n",
        "ax1 = axes[0, 0]\n",
        "classical_acc = classical_df['accuracy'] * 100\n",
        "hellsemble_acc = hellsemble_comparison['accuracy'] * 100\n",
        "\n",
        "positions = [1, 2]\n",
        "bp = ax1.boxplot([classical_acc, hellsemble_acc], positions=positions, widths=0.6,\n",
        "                  patch_artist=True, showmeans=True)\n",
        "bp['boxes'][0].set_facecolor('skyblue')\n",
        "bp['boxes'][1].set_facecolor('salmon')\n",
        "ax1.set_xticks(positions)\n",
        "ax1.set_xticklabels(['Classical', 'Hellsemble'])\n",
        "ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax1.set_title('Overall Accuracy Distribution', fontsize=14, fontweight='bold')\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add mean values as text\n",
        "mean_classical = classical_acc.mean()\n",
        "mean_hellsemble = hellsemble_acc.mean()\n",
        "ax1.text(1, mean_classical + 2, f'={mean_classical:.1f}%', ha='center', fontsize=10, fontweight='bold')\n",
        "ax1.text(2, mean_hellsemble + 2, f'={mean_hellsemble:.1f}%', ha='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Plot 2: Transition Sensitivity Distribution\n",
        "ax2 = axes[0, 1]\n",
        "classical_trans = classical_df['trans_sens']\n",
        "hellsemble_trans = hellsemble_comparison['trans_sens']\n",
        "\n",
        "bp2 = ax2.boxplot([classical_trans, hellsemble_trans], positions=positions, widths=0.6,\n",
        "                   patch_artist=True, showmeans=True)\n",
        "bp2['boxes'][0].set_facecolor('skyblue')\n",
        "bp2['boxes'][1].set_facecolor('salmon')\n",
        "ax2.set_xticks(positions)\n",
        "ax2.set_xticklabels(['Classical', 'Hellsemble'])\n",
        "ax2.set_ylabel('Transition Sensitivity (%)', fontsize=12)\n",
        "ax2.set_title('Transition Class Detection', fontsize=14, fontweight='bold')\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "mean_classical_trans = classical_trans.mean()\n",
        "mean_hellsemble_trans = hellsemble_trans.mean()\n",
        "ax2.text(1, mean_classical_trans + 2, f'={mean_classical_trans:.1f}%', ha='center', fontsize=10, fontweight='bold')\n",
        "ax2.text(2, mean_hellsemble_trans + 2, f'={mean_hellsemble_trans:.1f}%', ha='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Plot 3: Per-Class Sensitivity Comparison\n",
        "ax3 = axes[1, 0]\n",
        "class_metrics = pd.DataFrame({\n",
        "    'Walk': [classical_df['walk_sens'].mean(), hellsemble_comparison['walk_sens'].mean()],\n",
        "    'FoG': [classical_df['fog_sens'].mean(), hellsemble_comparison['fog_sens'].mean()],\n",
        "    'Transition': [classical_df['trans_sens'].mean(), hellsemble_comparison['trans_sens'].mean()]\n",
        "}, index=['Classical', 'Hellsemble'])\n",
        "\n",
        "class_metrics.plot(kind='bar', ax=ax3, color=['#3498db', '#e74c3c', '#2ecc71'], width=0.7)\n",
        "ax3.set_ylabel('Average Sensitivity (%)', fontsize=12)\n",
        "ax3.set_title('Average Sensitivity by Class', fontsize=14, fontweight='bold')\n",
        "ax3.set_xticklabels(ax3.get_xticklabels(), rotation=0)\n",
        "ax3.legend(title='Class', fontsize=10)\n",
        "ax3.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for container in ax3.containers:\n",
        "    ax3.bar_label(container, fmt='%.1f%%', padding=3)\n",
        "\n",
        "# Plot 4: Best Models Comparison\n",
        "ax4 = axes[1, 1]\n",
        "\n",
        "# Get top 5 overall models\n",
        "top_overall = all_results.nlargest(5, 'accuracy')\n",
        "model_labels = [f\"{row['model'][:15]}...\" if len(row['model']) > 15 else row['model']\n",
        "                for _, row in top_overall.iterrows()]\n",
        "colors_list = ['skyblue' if row['model_type'] == 'Classical' else 'salmon'\n",
        "               for _, row in top_overall.iterrows()]\n",
        "\n",
        "bars = ax4.barh(range(len(top_overall)), top_overall['accuracy'] * 100, color=colors_list)\n",
        "ax4.set_yticks(range(len(top_overall)))\n",
        "ax4.set_yticklabels(model_labels)\n",
        "ax4.set_xlabel('Accuracy (%)', fontsize=12)\n",
        "ax4.set_title('Top 5 Models Overall', fontsize=14, fontweight='bold')\n",
        "ax4.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, (_, row) in enumerate(top_overall.iterrows()):\n",
        "    ax4.text(row['accuracy'] * 100 + 1, i, f\"{row['accuracy']*100:.1f}%\",\n",
        "             va='center', fontsize=9)\n",
        "\n",
        "# Add legend\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor='skyblue', label='Classical'),\n",
        "                   Patch(facecolor='salmon', label='Hellsemble')]\n",
        "ax4.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n Visualizations generated!\")\n",
        "\n",
        "# ===== STATISTICAL COMPARISON =====\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"STATISTICAL COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "# T-test for accuracy\n",
        "t_stat, p_value = stats.ttest_ind(classical_df['accuracy'], hellsemble_comparison['accuracy'])\n",
        "print(f\"\\nT-test for Accuracy Difference:\")\n",
        "print(f\"  Classical mean: {classical_df['accuracy'].mean()*100:.2f}%\")\n",
        "print(f\"  Hellsemble mean: {hellsemble_comparison['accuracy'].mean()*100:.2f}%\")\n",
        "print(f\"  t-statistic: {t_stat:.4f}\")\n",
        "print(f\"  p-value: {p_value:.4f}\")\n",
        "if p_value < 0.05:\n",
        "    print(f\"   Statistically significant difference (p < 0.05)\")\n",
        "else:\n",
        "    print(f\"   No statistically significant difference (p >= 0.05)\")\n",
        "\n",
        "# T-test for transition sensitivity\n",
        "t_stat_trans, p_value_trans = stats.ttest_ind(classical_df['trans_sens'], hellsemble_comparison['trans_sens'])\n",
        "print(f\"\\nT-test for Transition Sensitivity Difference:\")\n",
        "print(f\"  Classical mean: {classical_df['trans_sens'].mean():.2f}%\")\n",
        "print(f\"  Hellsemble mean: {hellsemble_comparison['trans_sens'].mean():.2f}%\")\n",
        "print(f\"  t-statistic: {t_stat_trans:.4f}\")\n",
        "print(f\"  p-value: {p_value_trans:.4f}\")\n",
        "if p_value_trans < 0.05:\n",
        "    print(f\"   Statistically significant difference (p < 0.05)\")\n",
        "else:\n",
        "    print(f\"   No statistically significant difference (p >= 0.05)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" COMPREHENSIVE COMPARISON COMPLETE!\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AgMzoAf92tMH",
        "outputId": "4bd942d6-0e5d-4664-a76e-e94b6858b622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "COMPREHENSIVE COMPARISON: HELLSEMBLE VS CLASSICAL MODELS\n",
            "================================================================================\n",
            "\n",
            " Extracting classical model results from previous experiments...\n",
            " Extracted 15 classical model results\n",
            " Prepared 30 Hellsemble results\n",
            "\n",
            " Total experiments: 45\n",
            "   Classical: 15\n",
            "   Hellsemble: 30\n",
            "\n",
            "================================================================================\n",
            "COMPARISON 1: BEST OVERALL ACCURACY BY DATASET\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "Dataset: 2s-5feat\n",
            "================================================================================\n",
            "\n",
            "Top 5 Models:\n",
            "Rank   Type         Model                          Acc%     Trans%   FoG%     Walk%   \n",
            "--------------------------------------------------------------------------------\n",
            "1      Classical    XGBoost                         74.79%   18.31%   84.56%   84.54%\n",
            "2      Classical    Gradient Boosting               74.38%   22.54%   79.65%   85.29%\n",
            "3      Hellsemble   advanced_knn3_sequential        74.27%   11.27%   85.61%   84.92%\n",
            "4      Hellsemble   advanced_rf_sequential          74.27%   11.27%   85.61%   84.92%\n",
            "5      Hellsemble   mixed_mlp_greedy                73.55%    9.86%   84.21%   84.73%\n",
            "\n",
            "================================================================================\n",
            "Dataset: 3s-15feat\n",
            "================================================================================\n",
            "\n",
            "Top 5 Models:\n",
            "Rank   Type         Model                          Acc%     Trans%   FoG%     Walk%   \n",
            "--------------------------------------------------------------------------------\n",
            "1      Classical    Gradient Boosting               78.17%   46.48%   87.32%   84.18%\n",
            "2      Classical    XGBoost                         77.76%   47.18%   86.62%   83.54%\n",
            "3      Hellsemble   advanced_knn3_sequential        76.68%   36.62%   89.08%   83.54%\n",
            "4      Hellsemble   advanced_rf_sequential          76.68%   36.62%   89.08%   83.54%\n",
            "5      Classical    Random Forest                   75.47%   52.11%   81.34%   80.70%\n",
            "\n",
            "================================================================================\n",
            "Dataset: 4s-30feat\n",
            "================================================================================\n",
            "\n",
            "Top 5 Models:\n",
            "Rank   Type         Model                          Acc%     Trans%   FoG%     Walk%   \n",
            "--------------------------------------------------------------------------------\n",
            "1      Classical    Gradient Boosting               81.90%   66.20%   88.46%   86.06%\n",
            "2      Classical    XGBoost                         81.18%   66.20%   88.94%   83.65%\n",
            "3      Classical    Random Forest                   80.82%   65.49%   88.94%   83.17%\n",
            "4      Hellsemble   advanced_knn3_sequential        80.82%   60.56%   90.87%   84.62%\n",
            "5      Hellsemble   advanced_rf_sequential          80.82%   60.56%   90.87%   84.62%\n",
            "\n",
            "================================================================================\n",
            "COMPARISON 2: BEST TRANSITION CLASS SENSITIVITY\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "Dataset: 2s-5feat\n",
            "================================================================================\n",
            "\n",
            "Top 5 Models for Transition Detection:\n",
            "Rank   Type         Model                          Trans%   FoG%     Walk%    Acc%    \n",
            "--------------------------------------------------------------------------------\n",
            "1      Classical    RBF-SVM                         45.77%   50.18%   73.18%   62.34%\n",
            "2      Classical    Random Forest                   38.03%   72.63%   79.14%   71.16%\n",
            "3      Hellsemble   simple_rf_sequential            28.17%   61.75%   84.54%   69.50%\n",
            "4      Hellsemble   comprehensive_rf_sequential     28.17%   61.75%   84.54%   69.50%\n",
            "5      Hellsemble   simple_knn3_sequential          24.65%   62.81%   85.47%   69.81%\n",
            "\n",
            "================================================================================\n",
            "Dataset: 3s-15feat\n",
            "================================================================================\n",
            "\n",
            "Top 5 Models for Transition Detection:\n",
            "Rank   Type         Model                          Trans%   FoG%     Walk%    Acc%    \n",
            "--------------------------------------------------------------------------------\n",
            "1      Classical    RBF-SVM                         60.56%   71.48%   69.94%   68.73%\n",
            "2      Classical    Random Forest                   52.11%   81.34%   80.70%   75.47%\n",
            "3      Hellsemble   simple_knn3_greedy              50.00%   79.23%   74.05%   71.43%\n",
            "4      Classical    XGBoost                         47.18%   86.62%   83.54%   77.76%\n",
            "5      Hellsemble   simple_knn3_sequential          47.18%   80.28%   76.90%   72.51%\n",
            "\n",
            "================================================================================\n",
            "Dataset: 4s-30feat\n",
            "================================================================================\n",
            "\n",
            "Top 5 Models for Transition Detection:\n",
            "Rank   Type         Model                          Trans%   FoG%     Walk%    Acc%    \n",
            "--------------------------------------------------------------------------------\n",
            "1      Classical    RBF-SVM                         71.13%   85.10%   77.88%   78.85%\n",
            "2      Classical    XGBoost                         66.20%   88.94%   83.65%   81.18%\n",
            "3      Classical    Gradient Boosting               66.20%   88.46%   86.06%   81.90%\n",
            "4      Classical    Random Forest                   65.49%   88.94%   83.17%   80.82%\n",
            "5      Hellsemble   simple_knn3_sequential          61.97%   86.06%   82.69%   78.67%\n",
            "\n",
            "================================================================================\n",
            "COMPARISON 3: AVERAGE PERFORMANCE - CLASSICAL VS HELLSEMBLE\n",
            "================================================================================\n",
            "\n",
            "Average Performance:\n",
            "            accuracy  trans_sens  fog_sens  walk_sens\n",
            "model_type                                           \n",
            "Classical       0.75       46.71     80.84      81.08\n",
            "Hellsemble      0.75       40.33     81.69      81.87\n",
            "\n",
            "================================================================================\n",
            "COMPARISON 4: OVERALL CHAMPIONS\n",
            "================================================================================\n",
            "\n",
            " OVERALL BEST ACCURACY:\n",
            "1. [Classical] Gradient Boosting on 4s-30feat: 81.90% (Trans: 66.20%)\n",
            "2. [Classical] XGBoost on 4s-30feat: 81.18% (Trans: 66.20%)\n",
            "3. [Classical] Random Forest on 4s-30feat: 80.82% (Trans: 65.49%)\n",
            "\n",
            " OVERALL BEST TRANSITION SENSITIVITY:\n",
            "1. [Classical] RBF-SVM on 4s-30feat: 71.13% (Acc: 78.85%)\n",
            "2. [Classical] XGBoost on 4s-30feat: 66.20% (Acc: 81.18%)\n",
            "3. [Classical] Gradient Boosting on 4s-30feat: 66.20% (Acc: 81.90%)\n",
            "\n",
            " MOST BALANCED PERFORMANCE (all classes > 60%):\n",
            "1. [Classical] Gradient Boosting on 4s-30feat: Acc 81.90% | Trans 66.20% | FoG 88.46% | Walk 86.06%\n",
            "2. [Classical] XGBoost on 4s-30feat: Acc 81.18% | Trans 66.20% | FoG 88.94% | Walk 83.65%\n",
            "3. [Classical] Random Forest on 4s-30feat: Acc 80.82% | Trans 65.49% | FoG 88.94% | Walk 83.17%\n",
            "4. [Hellsemble] advanced_rf_sequential on 4s-30feat: Acc 80.82% | Trans 60.56% | FoG 90.87% | Walk 84.62%\n",
            "5. [Hellsemble] advanced_knn3_sequential on 4s-30feat: Acc 80.82% | Trans 60.56% | FoG 90.87% | Walk 84.62%\n",
            "\n",
            "================================================================================\n",
            "COMPARISON 5: DIRECT MATCHUP - BEST CLASSICAL VS BEST HELLSEMBLE\n",
            "================================================================================\n",
            "\n",
            "2S-5FEAT:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Metric               Classical Best                 Hellsemble Best                Winner         \n",
            "-----------------------------------------------------------------------------------------------\n",
            "Model                XGBoost                        advanced_knn3_sequential       -              \n",
            "Accuracy             74.79%                         74.27%                         Classical      \n",
            "Trans Sensitivity    18.31%                         11.27%                         Classical      \n",
            "FoG Sensitivity      84.56%                         85.61%                         Hellsemble     \n",
            "Walk Sensitivity     84.54%                         84.92%                         Hellsemble     \n",
            "\n",
            "3S-15FEAT:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Metric               Classical Best                 Hellsemble Best                Winner         \n",
            "-----------------------------------------------------------------------------------------------\n",
            "Model                Gradient Boosting              advanced_knn3_sequential       -              \n",
            "Accuracy             78.17%                         76.68%                         Classical      \n",
            "Trans Sensitivity    46.48%                         36.62%                         Classical      \n",
            "FoG Sensitivity      87.32%                         89.08%                         Hellsemble     \n",
            "Walk Sensitivity     84.18%                         83.54%                         Classical      \n",
            "\n",
            "4S-30FEAT:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Metric               Classical Best                 Hellsemble Best                Winner         \n",
            "-----------------------------------------------------------------------------------------------\n",
            "Model                Gradient Boosting              advanced_knn3_sequential       -              \n",
            "Accuracy             81.90%                         80.82%                         Classical      \n",
            "Trans Sensitivity    66.20%                         60.56%                         Classical      \n",
            "FoG Sensitivity      88.46%                         90.87%                         Hellsemble     \n",
            "Walk Sensitivity     86.06%                         84.62%                         Classical      \n",
            "\n",
            "================================================================================\n",
            "GENERATING VISUALIZATIONS...\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x1200 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Visualizations generated!\n",
            "\n",
            "================================================================================\n",
            "STATISTICAL COMPARISON\n",
            "================================================================================\n",
            "\n",
            "T-test for Accuracy Difference:\n",
            "  Classical mean: 75.07%\n",
            "  Hellsemble mean: 74.68%\n",
            "  t-statistic: 0.2771\n",
            "  p-value: 0.7830\n",
            "   No statistically significant difference (p >= 0.05)\n",
            "\n",
            "T-test for Transition Sensitivity Difference:\n",
            "  Classical mean: 46.71%\n",
            "  Hellsemble mean: 40.33%\n",
            "  t-statistic: 1.0314\n",
            "  p-value: 0.3081\n",
            "   No statistically significant difference (p >= 0.05)\n",
            "\n",
            "================================================================================\n",
            " COMPREHENSIVE COMPARISON COMPLETE!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IrIHzHo62yCR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}